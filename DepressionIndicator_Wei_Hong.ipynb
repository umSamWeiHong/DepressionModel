{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DepressionIndicator - Wei Hong.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/umSamWeiHong/DepressionModel/blob/master/DepressionIndicator_Wei_Hong.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Some random text\n"
      ],
      "metadata": {
        "id": "57Ni87HAOLMy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install tensorflow-gpu"
      ],
      "metadata": {
        "id": "4DRuGCsd1sx4"
      },
      "execution_count": 260,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !nvidia-smi"
      ],
      "metadata": {
        "id": "tT64KCDT1-rh"
      },
      "execution_count": 261,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "kC0AeXiRzVZ8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e5f6072-3c3a-426b-e982-62b34c49792a"
      },
      "execution_count": 262,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "tf.__version__"
      ],
      "metadata": {
        "id": "Mw7mWXC23I-P",
        "outputId": "e65bf4a6-246d-471b-e255-759c146ebea8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 263,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.8.2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 263
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Machine Learning Group Project/depression.csv')\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "e7QBwdb8wqhm",
        "outputId": "d87e25fb-976c-4b09-db52-d2c9a435cf17"
      },
      "execution_count": 264,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Code  Age_Numerical  Gender  Marital  Marital_problems  Religion_binary  \\\n",
              "0       1             34       0        0                 0                1   \n",
              "1       2             32       1        0                 0                1   \n",
              "2       3             33       0        0                 0                1   \n",
              "3       4             33       1        0                 1                1   \n",
              "4       5             39       1        0                 0                1   \n",
              "..    ...            ...     ...      ...               ...              ...   \n",
              "311   312             23       1        1                 0                0   \n",
              "312   313             36       0        1                 0                0   \n",
              "313   314             33       0        0                 0                0   \n",
              "314   315             25       1        1                 0                1   \n",
              "315   316             23       1        1                 0                1   \n",
              "\n",
              "     Religion_help  Med_or_not  Expenses  Monthly_expenses  ...  \\\n",
              "0                1           1         2                 1  ...   \n",
              "1                1           1         1                 0  ...   \n",
              "2                1           1         1                 0  ...   \n",
              "3                1           1         2                 1  ...   \n",
              "4                1           1         2                 1  ...   \n",
              "..             ...         ...       ...               ...  ...   \n",
              "311              1           1         2                 1  ...   \n",
              "312              0           0         2                 1  ...   \n",
              "313              0           1         2                 1  ...   \n",
              "314              0           1         0                 0  ...   \n",
              "315              1           1         0                 0  ...   \n",
              "\n",
              "     DASS_stress_numerical  MSPSS_family  MSPSS_friends  \\\n",
              "0                        0          27.2           24.0   \n",
              "1                        2          28.0           28.0   \n",
              "2                        0          28.0           28.0   \n",
              "3                       18          25.2           21.2   \n",
              "4                        2          26.0           20.0   \n",
              "..                     ...           ...            ...   \n",
              "311                      8          25.2           25.2   \n",
              "312                      0          23.2           20.0   \n",
              "313                      0          25.2           19.2   \n",
              "314                     26          14.0           13.2   \n",
              "315                      6          16.0           16.0   \n",
              "\n",
              "     MSPSS_significant_others  DASS_depression_binary  \\\n",
              "0                        26.0                       0   \n",
              "1                        28.0                       0   \n",
              "2                        28.0                       0   \n",
              "3                        24.0                       1   \n",
              "4                        28.0                       0   \n",
              "..                        ...                     ...   \n",
              "311                      27.2                       0   \n",
              "312                      24.0                       0   \n",
              "313                      27.2                       0   \n",
              "314                      13.2                       1   \n",
              "315                      17.2                       0   \n",
              "\n",
              "     DASS_depression_severity  DASS_anxiety_binary  DASS_anxiety_severity  \\\n",
              "0                           0                    0                      0   \n",
              "1                           0                    0                      0   \n",
              "2                           0                    0                      0   \n",
              "3                           2                    1                      4   \n",
              "4                           0                    0                      0   \n",
              "..                        ...                  ...                    ...   \n",
              "311                         0                    0                      0   \n",
              "312                         0                    0                      0   \n",
              "313                         0                    0                      0   \n",
              "314                         4                    1                      2   \n",
              "315                         0                    0                      0   \n",
              "\n",
              "     DASS_stress_binary  DASS_stress_severity  \n",
              "0                     0                     0  \n",
              "1                     0                     0  \n",
              "2                     0                     0  \n",
              "3                     1                     1  \n",
              "4                     0                     0  \n",
              "..                  ...                   ...  \n",
              "311                   0                     0  \n",
              "312                   0                     0  \n",
              "313                   0                     0  \n",
              "314                   1                     2  \n",
              "315                   0                     0  \n",
              "\n",
              "[316 rows x 34 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9efc02eb-bbcd-4e22-8877-ecb170586ffe\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Code</th>\n",
              "      <th>Age_Numerical</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Marital</th>\n",
              "      <th>Marital_problems</th>\n",
              "      <th>Religion_binary</th>\n",
              "      <th>Religion_help</th>\n",
              "      <th>Med_or_not</th>\n",
              "      <th>Expenses</th>\n",
              "      <th>Monthly_expenses</th>\n",
              "      <th>...</th>\n",
              "      <th>DASS_stress_numerical</th>\n",
              "      <th>MSPSS_family</th>\n",
              "      <th>MSPSS_friends</th>\n",
              "      <th>MSPSS_significant_others</th>\n",
              "      <th>DASS_depression_binary</th>\n",
              "      <th>DASS_depression_severity</th>\n",
              "      <th>DASS_anxiety_binary</th>\n",
              "      <th>DASS_anxiety_severity</th>\n",
              "      <th>DASS_stress_binary</th>\n",
              "      <th>DASS_stress_severity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>34</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>27.2</td>\n",
              "      <td>24.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>28.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>33</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>18</td>\n",
              "      <td>25.2</td>\n",
              "      <td>21.2</td>\n",
              "      <td>24.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>26.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>311</th>\n",
              "      <td>312</td>\n",
              "      <td>23</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>8</td>\n",
              "      <td>25.2</td>\n",
              "      <td>25.2</td>\n",
              "      <td>27.2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>312</th>\n",
              "      <td>313</td>\n",
              "      <td>36</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>23.2</td>\n",
              "      <td>20.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>313</th>\n",
              "      <td>314</td>\n",
              "      <td>33</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>25.2</td>\n",
              "      <td>19.2</td>\n",
              "      <td>27.2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>314</th>\n",
              "      <td>315</td>\n",
              "      <td>25</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>26</td>\n",
              "      <td>14.0</td>\n",
              "      <td>13.2</td>\n",
              "      <td>13.2</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>315</th>\n",
              "      <td>316</td>\n",
              "      <td>23</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>6</td>\n",
              "      <td>16.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>17.2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>316 rows Ã— 34 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9efc02eb-bbcd-4e22-8877-ecb170586ffe')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9efc02eb-bbcd-4e22-8877-ecb170586ffe button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9efc02eb-bbcd-4e22-8877-ecb170586ffe');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 264
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "X = df\n",
        "y = df['DASS_depression_severity']\n",
        "\n",
        "X = X.drop(columns='DASS_depression_severity')\n",
        "print(Counter(y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNXFbHsVh0ti",
        "outputId": "e87b5746-e072-4e30-9309-faa78bcba53e"
      },
      "execution_count": 265,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({0: 201, 1: 49, 2: 37, 3: 16, 4: 13})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import RandomOverSampler\n",
        "over = RandomOverSampler(sampling_strategy={0: 201, 1: 50, 2: 50, 3: 30, 4: 30})\n",
        "X, y = over.fit_resample(X, y)\n",
        "print(f\"Oversampled: {Counter(y)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sY-KFRIjq0tH",
        "outputId": "03b7be98-6494-4271-d62f-875a862a9024"
      },
      "execution_count": 266,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Oversampled: Counter({0: 201, 2: 50, 1: 50, 3: 30, 4: 30})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "under = RandomUnderSampler(sampling_strategy={0: 100, 1: 50, 2: 50, 3: 30, 4: 30})\n",
        "X, y = under.fit_resample(X, y)\n",
        "print(f\"Combined Random Sampling: {Counter(y)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ntu7Uxx6q0q3",
        "outputId": "a38282be-3aef-405d-a2bf-c3c14fb2e987"
      },
      "execution_count": 267,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combined Random Sampling: Counter({0: 100, 1: 50, 2: 50, 3: 30, 4: 30})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "One hot encoding for categorical data"
      ],
      "metadata": {
        "id": "5GuktUMVpDav"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "ohe = OneHotEncoder(sparse=False)\n",
        "X[['Alone','Friends/Coursemates','Family']] = ohe.fit_transform(X['Living_with1'].values.reshape(-1,1))\n",
        "X[['< RM1000','RM1000 - 3000','> RM3000']] = ohe.fit_transform(X['Expenses'].values.reshape(-1,1))\n",
        "y = ohe.fit_transform(y.values.reshape(-1,1))\n",
        "\n",
        "X = X.drop(columns=['Living_with1','Expenses'])\n",
        "y"
      ],
      "metadata": {
        "id": "VyBPO23hnrw9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50855454-bda7-41bb-f874-be888b0682e0"
      },
      "execution_count": 268,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., 0., 1.],\n",
              "       [0., 0., 0., 0., 1.],\n",
              "       [0., 0., 0., 0., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 268
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remove unnecessary columns (features):"
      ],
      "metadata": {
        "id": "H-cuLUfshz2j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.columns)\n",
        "df.drop(columns=['Code','Residence_high_COVID1','Living_with','Monthly_expenses',\n",
        "                 'DASS_depression_numerical','DASS_anxiety_numerical','DASS_stress_numerical',\n",
        "                 'DASS_depression_binary','DASS_anxiety_binary','DASS_anxiety_severity','DASS_stress_binary','DASS_stress_severity',\n",
        "                #  'Religion_binary','Med_or_not',\n",
        "                 ],\n",
        "        inplace=True, axis=1)\n",
        "print(df.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hN1ifvxhzU0",
        "outputId": "0965e5fb-f50d-41d9-8323-c50dbd867643"
      },
      "execution_count": 269,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Code', 'Age_Numerical', 'Gender', 'Marital', 'Marital_problems',\n",
            "       'Religion_binary', 'Religion_help', 'Med_or_not', 'Expenses',\n",
            "       'Monthly_expenses', 'Living_with1', 'Living_with', 'Worry_family',\n",
            "       'Routine_loss', 'Class_hours', 'Stress_class_disrupted',\n",
            "       'Medical_illness', 'Mental_illness', 'COVID_symptoms',\n",
            "       'Residence_high_COVID1', 'Residence_high_COVID', 'Quarantine',\n",
            "       'DASS_depression_numerical', 'DASS_anxiety_numerical',\n",
            "       'DASS_stress_numerical', 'MSPSS_family', 'MSPSS_friends',\n",
            "       'MSPSS_significant_others', 'DASS_depression_binary',\n",
            "       'DASS_depression_severity', 'DASS_anxiety_binary',\n",
            "       'DASS_anxiety_severity', 'DASS_stress_binary', 'DASS_stress_severity'],\n",
            "      dtype='object')\n",
            "Index(['Age_Numerical', 'Gender', 'Marital', 'Marital_problems',\n",
            "       'Religion_binary', 'Religion_help', 'Med_or_not', 'Expenses',\n",
            "       'Living_with1', 'Worry_family', 'Routine_loss', 'Class_hours',\n",
            "       'Stress_class_disrupted', 'Medical_illness', 'Mental_illness',\n",
            "       'COVID_symptoms', 'Residence_high_COVID', 'Quarantine', 'MSPSS_family',\n",
            "       'MSPSS_friends', 'MSPSS_significant_others',\n",
            "       'DASS_depression_severity'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split the dataset into the training set and test set"
      ],
      "metadata": {
        "id": "fxeFideitBCm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
        "print(X_train.shape, y_train.shape)\n",
        "print(X_test.shape, y_test.shape)"
      ],
      "metadata": {
        "id": "w2TwMny0Dio1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76b48a86-1446-42b0-b5e3-6d5572a4d037"
      },
      "execution_count": 270,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(182, 37) (182, 5)\n",
            "(78, 37) (78, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Call the method below for feature normalisation (for numerical values):"
      ],
      "metadata": {
        "id": "pn0aVR1DVljM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "def featureNormalisation():\n",
        "  numeric_data = ['Age_Numerical', 'Class_hours', 'MSPSS_family', 'MSPSS_friends', 'MSPSS_significant_others']\n",
        "\n",
        "  ct = ColumnTransformer([('scaler', StandardScaler(), numeric_data)], remainder='passthrough')\n",
        "\n",
        "  X_train_scaled = ct.fit_transform(X_train)\n",
        "  # print(pd.DataFrame(X_train_scaled, columns = ct.get_feature_names_out()))\n",
        "  # the test set uses the fitted scaler in train dataset to transform in the test set\n",
        "  X_test_scaled = ct.transform(X_test)\n",
        "  return X_train_scaled, X_test_scaled, ct.get_feature_names_out()"
      ],
      "metadata": {
        "id": "gSrRWbUfCzTe"
      },
      "execution_count": 271,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use feature normalisation:"
      ],
      "metadata": {
        "id": "LoCFdvM2bz21"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_scaled, X_test_scaled, features = featureNormalisation()"
      ],
      "metadata": {
        "id": "ULvUOq-OXcUP"
      },
      "execution_count": 272,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Neural network (Deep learning):"
      ],
      "metadata": {
        "id": "bf5z7sksnU8-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U keras-tuner\n",
        "\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import kerastuner as kt\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "def model_builder(hp):\n",
        "  model = Sequential()\n",
        "  activation = hp.Choice('activation', values=['relu','elu','tanh'])\n",
        "  # activation = 'relu'\n",
        "  hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])  \n",
        "  hp_units1 = hp.Int('units1', min_value=1, max_value=100, step=2)\n",
        "  hp_units2 = hp.Int('units2', min_value=1, max_value=100, step=2)\n",
        "  model.add(Dense(units=X.shape[1], activation=activation))\n",
        "  model.add(Dense(units=hp_units1, activation=activation))\n",
        "  model.add(keras.layers.Dropout(0.2)) \n",
        "  model.add(Dense(units=hp_units2, activation=activation, kernel_regularizer=keras.regularizers.l1()))\n",
        "  model.add(Dense(5, activation='softmax'))\n",
        "\n",
        "  model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
        "  # model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "                loss=keras.losses.CategoricalCrossentropy(),\n",
        "                metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "# def model_builder(hp):\n",
        "#   model = Sequential()\n",
        "#   activation = 'relu'\n",
        "#   hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
        "  \n",
        "#   hp_units1 = hp.Int('units1', min_value=1, max_value=50, step=1)\n",
        "#   # hp_units2 = hp.Int('units2', min_value=1, max_value=50, step=1)\n",
        "#   # hp_units3 = hp.Int('units3', min_value=1, max_value=50, step=1)\n",
        "#   hp_dropout1 = hp.Float('dropout1', min_value=0, max_value=0.4)\n",
        "#   model.add(Dense(units=25, activation=activation))\n",
        "#   model.add(Dense(units=hp_units1, activation=activation))\n",
        "#   # model.add(Dense(units=hp_units2, activation=activation))\n",
        "#   model.add(keras.layers.Dropout(hp_dropout1))\n",
        "#   # model.add(Dense(units=hp_units3, activation=activation))    \n",
        "#   model.add(Dense(5, activation='softmax'))\n",
        "\n",
        "#   model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
        "#                 loss=keras.losses.CategoricalCrossentropy(),\n",
        "#                 metrics=['accuracy'])\n",
        "#   return model"
      ],
      "metadata": {
        "id": "VCnFqpo9HqpT"
      },
      "execution_count": 309,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner = kt.Hyperband(model_builder,\n",
        "                     objective='val_accuracy',\n",
        "                     max_epochs=20,\n",
        "                     factor=3,\n",
        "                     directory='my_dir',\n",
        "                     project_name='keras-tuning',\n",
        "                     overwrite=True)\n",
        "tuner.search_space_summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hbNQJfcNGkyT",
        "outputId": "41b8cb22-77ad-440d-95fa-80ca629e5723"
      },
      "execution_count": 438,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Search space summary\n",
            "Default search space size: 4\n",
            "activation (Choice)\n",
            "{'default': 'relu', 'conditions': [], 'values': ['relu', 'elu', 'tanh'], 'ordered': False}\n",
            "learning_rate (Choice)\n",
            "{'default': 0.01, 'conditions': [], 'values': [0.01, 0.001, 0.0001], 'ordered': True}\n",
            "units1 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 1, 'max_value': 100, 'step': 2, 'sampling': None}\n",
            "units2 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 1, 'max_value': 100, 'step': 2, 'sampling': None}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
        "# Perform hypertuning\n",
        "tuner.search(X_train_scaled, y_train, epochs=10, validation_split=0.2, callbacks=[stop_early])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZqAyJpqsIBvG",
        "outputId": "31240818-d4f2-4789-e220-112c3730793f"
      },
      "execution_count": 439,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 30 Complete [00h 00m 02s]\n",
            "val_accuracy: 0.5675675868988037\n",
            "\n",
            "Best val_accuracy So Far: 0.9189189076423645\n",
            "Total elapsed time: 00h 00m 51s\n",
            "INFO:tensorflow:Oracle triggered exit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_hps=tuner.get_best_hyperparameters()[0]\n",
        "h_model = tuner.hypermodel.build(best_hps)\n",
        "history = h_model.fit(X_train_scaled, y_train, epochs=200, validation_split=0.2)"
      ],
      "metadata": {
        "id": "CHmXUO9-IHjl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54d63123-1f23-4e12-f191-95f95c7af336"
      },
      "execution_count": 459,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "5/5 [==============================] - 1s 45ms/step - loss: 14.9028 - accuracy: 0.1862 - val_loss: 11.8491 - val_accuracy: 0.4054\n",
            "Epoch 2/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 9.5816 - accuracy: 0.3724 - val_loss: 6.9125 - val_accuracy: 0.2162\n",
            "Epoch 3/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 6.8982 - accuracy: 0.2759 - val_loss: 5.7712 - val_accuracy: 0.4865\n",
            "Epoch 4/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 5.8079 - accuracy: 0.5103 - val_loss: 5.2257 - val_accuracy: 0.5405\n",
            "Epoch 5/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 5.1920 - accuracy: 0.4897 - val_loss: 4.7471 - val_accuracy: 0.5405\n",
            "Epoch 6/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 4.7092 - accuracy: 0.6138 - val_loss: 4.2044 - val_accuracy: 0.7568\n",
            "Epoch 7/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 4.3012 - accuracy: 0.5793 - val_loss: 3.7297 - val_accuracy: 0.9189\n",
            "Epoch 8/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 3.9591 - accuracy: 0.6069 - val_loss: 3.4176 - val_accuracy: 0.8378\n",
            "Epoch 9/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 3.5553 - accuracy: 0.7034 - val_loss: 3.1518 - val_accuracy: 0.7838\n",
            "Epoch 10/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 3.2430 - accuracy: 0.7586 - val_loss: 2.9102 - val_accuracy: 0.7568\n",
            "Epoch 11/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 2.9289 - accuracy: 0.7931 - val_loss: 2.5665 - val_accuracy: 0.8919\n",
            "Epoch 12/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 2.6260 - accuracy: 0.8483 - val_loss: 2.3518 - val_accuracy: 0.9459\n",
            "Epoch 13/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 2.4432 - accuracy: 0.8414 - val_loss: 2.1485 - val_accuracy: 0.9730\n",
            "Epoch 14/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 2.2702 - accuracy: 0.8000 - val_loss: 2.0329 - val_accuracy: 0.9189\n",
            "Epoch 15/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 2.1292 - accuracy: 0.8414 - val_loss: 1.8868 - val_accuracy: 0.9459\n",
            "Epoch 16/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 1.9911 - accuracy: 0.8414 - val_loss: 1.7793 - val_accuracy: 0.9189\n",
            "Epoch 17/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 1.8885 - accuracy: 0.8414 - val_loss: 1.6347 - val_accuracy: 0.9730\n",
            "Epoch 18/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.7359 - accuracy: 0.8828 - val_loss: 1.6082 - val_accuracy: 0.9189\n",
            "Epoch 19/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 1.6406 - accuracy: 0.8759 - val_loss: 1.4309 - val_accuracy: 0.9730\n",
            "Epoch 20/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 1.5517 - accuracy: 0.8897 - val_loss: 1.4300 - val_accuracy: 0.8919\n",
            "Epoch 21/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 1.4447 - accuracy: 0.9172 - val_loss: 1.3073 - val_accuracy: 0.9730\n",
            "Epoch 22/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.3752 - accuracy: 0.9034 - val_loss: 1.2338 - val_accuracy: 1.0000\n",
            "Epoch 23/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 1.3194 - accuracy: 0.8759 - val_loss: 1.2234 - val_accuracy: 0.9459\n",
            "Epoch 24/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 1.2635 - accuracy: 0.9103 - val_loss: 1.1548 - val_accuracy: 0.9189\n",
            "Epoch 25/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.2529 - accuracy: 0.8966 - val_loss: 1.0925 - val_accuracy: 1.0000\n",
            "Epoch 26/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.1864 - accuracy: 0.9241 - val_loss: 1.1818 - val_accuracy: 0.8649\n",
            "Epoch 27/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.1432 - accuracy: 0.8966 - val_loss: 1.0605 - val_accuracy: 0.9459\n",
            "Epoch 28/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 1.0793 - accuracy: 0.9034 - val_loss: 0.9536 - val_accuracy: 0.9730\n",
            "Epoch 29/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.0650 - accuracy: 0.8966 - val_loss: 0.9021 - val_accuracy: 0.9730\n",
            "Epoch 30/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.0277 - accuracy: 0.9034 - val_loss: 1.1057 - val_accuracy: 0.7838\n",
            "Epoch 31/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.0051 - accuracy: 0.9172 - val_loss: 0.9801 - val_accuracy: 0.8378\n",
            "Epoch 32/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.9764 - accuracy: 0.9034 - val_loss: 0.8777 - val_accuracy: 0.9189\n",
            "Epoch 33/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.9785 - accuracy: 0.8759 - val_loss: 0.8313 - val_accuracy: 0.9730\n",
            "Epoch 34/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.9074 - accuracy: 0.9241 - val_loss: 0.8882 - val_accuracy: 0.9189\n",
            "Epoch 35/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.8547 - accuracy: 0.9379 - val_loss: 0.8838 - val_accuracy: 0.8919\n",
            "Epoch 36/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.8494 - accuracy: 0.9241 - val_loss: 0.7157 - val_accuracy: 0.9730\n",
            "Epoch 37/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.8094 - accuracy: 0.9172 - val_loss: 0.7789 - val_accuracy: 0.8919\n",
            "Epoch 38/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.7597 - accuracy: 0.9379 - val_loss: 0.7526 - val_accuracy: 0.9459\n",
            "Epoch 39/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.7236 - accuracy: 0.9517 - val_loss: 0.9600 - val_accuracy: 0.8378\n",
            "Epoch 40/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.8347 - accuracy: 0.8828 - val_loss: 0.8428 - val_accuracy: 0.7838\n",
            "Epoch 41/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.8773 - accuracy: 0.8483 - val_loss: 0.6421 - val_accuracy: 0.9730\n",
            "Epoch 42/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.7775 - accuracy: 0.8897 - val_loss: 0.6780 - val_accuracy: 0.9459\n",
            "Epoch 43/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.7456 - accuracy: 0.9517 - val_loss: 0.7524 - val_accuracy: 0.8378\n",
            "Epoch 44/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6777 - accuracy: 0.9517 - val_loss: 0.5947 - val_accuracy: 1.0000\n",
            "Epoch 45/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.6513 - accuracy: 0.9586 - val_loss: 0.6091 - val_accuracy: 0.9459\n",
            "Epoch 46/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.6257 - accuracy: 0.9517 - val_loss: 0.7641 - val_accuracy: 0.8378\n",
            "Epoch 47/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6075 - accuracy: 0.9517 - val_loss: 0.6154 - val_accuracy: 0.9189\n",
            "Epoch 48/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.5431 - accuracy: 0.9724 - val_loss: 0.5945 - val_accuracy: 0.9189\n",
            "Epoch 49/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.5219 - accuracy: 0.9724 - val_loss: 0.4923 - val_accuracy: 0.9730\n",
            "Epoch 50/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.5134 - accuracy: 0.9655 - val_loss: 0.5789 - val_accuracy: 0.9189\n",
            "Epoch 51/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4742 - accuracy: 0.9862 - val_loss: 0.4672 - val_accuracy: 0.9459\n",
            "Epoch 52/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4639 - accuracy: 0.9793 - val_loss: 0.4478 - val_accuracy: 0.9459\n",
            "Epoch 53/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4412 - accuracy: 0.9931 - val_loss: 0.4518 - val_accuracy: 0.9459\n",
            "Epoch 54/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4358 - accuracy: 0.9655 - val_loss: 0.4497 - val_accuracy: 0.9459\n",
            "Epoch 55/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.4047 - accuracy: 0.9862 - val_loss: 0.3957 - val_accuracy: 1.0000\n",
            "Epoch 56/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3815 - accuracy: 0.9862 - val_loss: 0.5204 - val_accuracy: 0.9189\n",
            "Epoch 57/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3796 - accuracy: 0.9862 - val_loss: 0.4216 - val_accuracy: 0.9459\n",
            "Epoch 58/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4018 - accuracy: 0.9793 - val_loss: 0.6550 - val_accuracy: 0.8108\n",
            "Epoch 59/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4379 - accuracy: 0.9379 - val_loss: 0.3649 - val_accuracy: 1.0000\n",
            "Epoch 60/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4319 - accuracy: 0.9586 - val_loss: 0.4092 - val_accuracy: 0.9459\n",
            "Epoch 61/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4096 - accuracy: 0.9655 - val_loss: 0.7844 - val_accuracy: 0.7297\n",
            "Epoch 62/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.4929 - accuracy: 0.9103 - val_loss: 0.3456 - val_accuracy: 1.0000\n",
            "Epoch 63/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4041 - accuracy: 0.9724 - val_loss: 0.4336 - val_accuracy: 0.9459\n",
            "Epoch 64/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3998 - accuracy: 0.9793 - val_loss: 0.5238 - val_accuracy: 0.8919\n",
            "Epoch 65/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.5139 - accuracy: 0.9448 - val_loss: 0.3645 - val_accuracy: 1.0000\n",
            "Epoch 66/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.4584 - accuracy: 0.9517 - val_loss: 0.5101 - val_accuracy: 0.9189\n",
            "Epoch 67/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4086 - accuracy: 0.9448 - val_loss: 0.3905 - val_accuracy: 0.9459\n",
            "Epoch 68/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3763 - accuracy: 0.9586 - val_loss: 0.4184 - val_accuracy: 0.9189\n",
            "Epoch 69/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.3994 - accuracy: 0.9448 - val_loss: 0.3153 - val_accuracy: 0.9730\n",
            "Epoch 70/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.3684 - accuracy: 0.9655 - val_loss: 0.5408 - val_accuracy: 0.8919\n",
            "Epoch 71/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3634 - accuracy: 0.9724 - val_loss: 0.4955 - val_accuracy: 0.9189\n",
            "Epoch 72/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.3252 - accuracy: 0.9931 - val_loss: 0.3564 - val_accuracy: 0.9730\n",
            "Epoch 73/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3262 - accuracy: 0.9793 - val_loss: 0.2807 - val_accuracy: 1.0000\n",
            "Epoch 74/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3338 - accuracy: 0.9793 - val_loss: 0.3598 - val_accuracy: 0.9730\n",
            "Epoch 75/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3014 - accuracy: 0.9862 - val_loss: 0.3290 - val_accuracy: 0.9459\n",
            "Epoch 76/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2675 - accuracy: 1.0000 - val_loss: 0.2783 - val_accuracy: 0.9730\n",
            "Epoch 77/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2592 - accuracy: 0.9862 - val_loss: 0.2837 - val_accuracy: 0.9459\n",
            "Epoch 78/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2490 - accuracy: 0.9931 - val_loss: 0.3938 - val_accuracy: 0.8919\n",
            "Epoch 79/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2561 - accuracy: 0.9862 - val_loss: 0.2770 - val_accuracy: 0.9730\n",
            "Epoch 80/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.2305 - accuracy: 1.0000 - val_loss: 0.3015 - val_accuracy: 0.9459\n",
            "Epoch 81/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2272 - accuracy: 0.9862 - val_loss: 0.2526 - val_accuracy: 0.9730\n",
            "Epoch 82/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.2638 - accuracy: 0.9724 - val_loss: 0.3642 - val_accuracy: 0.9189\n",
            "Epoch 83/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2286 - accuracy: 0.9931 - val_loss: 0.2743 - val_accuracy: 0.9730\n",
            "Epoch 84/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.2168 - accuracy: 1.0000 - val_loss: 0.2996 - val_accuracy: 0.9459\n",
            "Epoch 85/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2225 - accuracy: 0.9862 - val_loss: 0.2509 - val_accuracy: 0.9730\n",
            "Epoch 86/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.2638 - accuracy: 0.9724 - val_loss: 0.2284 - val_accuracy: 1.0000\n",
            "Epoch 87/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2630 - accuracy: 0.9793 - val_loss: 0.5464 - val_accuracy: 0.7838\n",
            "Epoch 88/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2992 - accuracy: 0.9517 - val_loss: 0.3319 - val_accuracy: 0.9189\n",
            "Epoch 89/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.2529 - accuracy: 0.9724 - val_loss: 0.2783 - val_accuracy: 0.9459\n",
            "Epoch 90/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2584 - accuracy: 0.9862 - val_loss: 0.6287 - val_accuracy: 0.8919\n",
            "Epoch 91/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3177 - accuracy: 0.9793 - val_loss: 0.4289 - val_accuracy: 0.8919\n",
            "Epoch 92/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3073 - accuracy: 0.9724 - val_loss: 0.3318 - val_accuracy: 0.9189\n",
            "Epoch 93/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3207 - accuracy: 0.9517 - val_loss: 0.4349 - val_accuracy: 0.9189\n",
            "Epoch 94/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2966 - accuracy: 0.9931 - val_loss: 0.2759 - val_accuracy: 1.0000\n",
            "Epoch 95/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.2931 - accuracy: 0.9862 - val_loss: 0.3176 - val_accuracy: 0.9459\n",
            "Epoch 96/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.2635 - accuracy: 0.9862 - val_loss: 0.2821 - val_accuracy: 0.9730\n",
            "Epoch 97/200\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2380 - accuracy: 0.9931 - val_loss: 0.2640 - val_accuracy: 0.9730\n",
            "Epoch 98/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.2162 - accuracy: 1.0000 - val_loss: 0.2615 - val_accuracy: 0.9730\n",
            "Epoch 99/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.2196 - accuracy: 0.9931 - val_loss: 0.3234 - val_accuracy: 0.8919\n",
            "Epoch 100/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2185 - accuracy: 0.9931 - val_loss: 0.2264 - val_accuracy: 0.9730\n",
            "Epoch 101/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.2267 - accuracy: 0.9862 - val_loss: 0.4285 - val_accuracy: 0.8919\n",
            "Epoch 102/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.2617 - accuracy: 0.9724 - val_loss: 0.3604 - val_accuracy: 0.9189\n",
            "Epoch 103/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2380 - accuracy: 0.9862 - val_loss: 0.3248 - val_accuracy: 0.9459\n",
            "Epoch 104/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2329 - accuracy: 0.9862 - val_loss: 0.3696 - val_accuracy: 0.8919\n",
            "Epoch 105/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.2052 - accuracy: 1.0000 - val_loss: 0.2614 - val_accuracy: 0.9459\n",
            "Epoch 106/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.2094 - accuracy: 0.9931 - val_loss: 0.3165 - val_accuracy: 0.8919\n",
            "Epoch 107/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1999 - accuracy: 1.0000 - val_loss: 0.2438 - val_accuracy: 0.9730\n",
            "Epoch 108/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1847 - accuracy: 1.0000 - val_loss: 0.4459 - val_accuracy: 0.8919\n",
            "Epoch 109/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2036 - accuracy: 0.9724 - val_loss: 0.2557 - val_accuracy: 0.9459\n",
            "Epoch 110/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1991 - accuracy: 1.0000 - val_loss: 0.3383 - val_accuracy: 0.8919\n",
            "Epoch 111/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1837 - accuracy: 1.0000 - val_loss: 0.2825 - val_accuracy: 0.9189\n",
            "Epoch 112/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1879 - accuracy: 0.9931 - val_loss: 0.2642 - val_accuracy: 0.9459\n",
            "Epoch 113/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1968 - accuracy: 0.9862 - val_loss: 0.3174 - val_accuracy: 0.9189\n",
            "Epoch 114/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1769 - accuracy: 0.9931 - val_loss: 0.2150 - val_accuracy: 0.9730\n",
            "Epoch 115/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1697 - accuracy: 1.0000 - val_loss: 0.2083 - val_accuracy: 0.9730\n",
            "Epoch 116/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1650 - accuracy: 1.0000 - val_loss: 0.2461 - val_accuracy: 0.9459\n",
            "Epoch 117/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1624 - accuracy: 0.9931 - val_loss: 0.2279 - val_accuracy: 0.9730\n",
            "Epoch 118/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1704 - accuracy: 0.9931 - val_loss: 0.1867 - val_accuracy: 0.9730\n",
            "Epoch 119/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1806 - accuracy: 0.9793 - val_loss: 0.4086 - val_accuracy: 0.8919\n",
            "Epoch 120/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1887 - accuracy: 0.9931 - val_loss: 0.2127 - val_accuracy: 0.9459\n",
            "Epoch 121/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1785 - accuracy: 0.9931 - val_loss: 0.4650 - val_accuracy: 0.8649\n",
            "Epoch 122/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.2184 - accuracy: 0.9793 - val_loss: 0.3016 - val_accuracy: 0.9189\n",
            "Epoch 123/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2496 - accuracy: 0.9724 - val_loss: 0.4686 - val_accuracy: 0.8649\n",
            "Epoch 124/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2250 - accuracy: 0.9793 - val_loss: 0.2926 - val_accuracy: 0.9189\n",
            "Epoch 125/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2111 - accuracy: 1.0000 - val_loss: 0.2727 - val_accuracy: 0.9730\n",
            "Epoch 126/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1925 - accuracy: 0.9931 - val_loss: 0.1976 - val_accuracy: 0.9730\n",
            "Epoch 127/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.1949 - accuracy: 0.9931 - val_loss: 0.2178 - val_accuracy: 0.9730\n",
            "Epoch 128/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2062 - accuracy: 0.9793 - val_loss: 0.2639 - val_accuracy: 0.9189\n",
            "Epoch 129/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1894 - accuracy: 0.9931 - val_loss: 0.1838 - val_accuracy: 0.9730\n",
            "Epoch 130/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2012 - accuracy: 0.9793 - val_loss: 0.3918 - val_accuracy: 0.8649\n",
            "Epoch 131/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1953 - accuracy: 0.9931 - val_loss: 0.2659 - val_accuracy: 0.9459\n",
            "Epoch 132/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1786 - accuracy: 1.0000 - val_loss: 0.3757 - val_accuracy: 0.8919\n",
            "Epoch 133/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1916 - accuracy: 0.9931 - val_loss: 0.1972 - val_accuracy: 0.9730\n",
            "Epoch 134/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1741 - accuracy: 1.0000 - val_loss: 0.4653 - val_accuracy: 0.8919\n",
            "Epoch 135/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1864 - accuracy: 1.0000 - val_loss: 0.2018 - val_accuracy: 1.0000\n",
            "Epoch 136/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3404 - accuracy: 0.9379 - val_loss: 0.3128 - val_accuracy: 0.9459\n",
            "Epoch 137/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3850 - accuracy: 0.9310 - val_loss: 1.4689 - val_accuracy: 0.7297\n",
            "Epoch 138/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4977 - accuracy: 0.8897 - val_loss: 0.5893 - val_accuracy: 0.9189\n",
            "Epoch 139/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6707 - accuracy: 0.8897 - val_loss: 0.3832 - val_accuracy: 1.0000\n",
            "Epoch 140/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4829 - accuracy: 0.9517 - val_loss: 0.9500 - val_accuracy: 0.8649\n",
            "Epoch 141/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4823 - accuracy: 0.9655 - val_loss: 0.4203 - val_accuracy: 0.9459\n",
            "Epoch 142/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.3998 - accuracy: 0.9724 - val_loss: 0.4402 - val_accuracy: 0.9459\n",
            "Epoch 143/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3657 - accuracy: 0.9862 - val_loss: 0.3119 - val_accuracy: 0.9730\n",
            "Epoch 144/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3775 - accuracy: 0.9586 - val_loss: 0.4911 - val_accuracy: 0.9459\n",
            "Epoch 145/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3755 - accuracy: 0.9655 - val_loss: 0.3060 - val_accuracy: 0.9730\n",
            "Epoch 146/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3540 - accuracy: 0.9379 - val_loss: 0.3225 - val_accuracy: 0.9730\n",
            "Epoch 147/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3298 - accuracy: 0.9793 - val_loss: 0.8095 - val_accuracy: 0.8378\n",
            "Epoch 148/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3963 - accuracy: 0.9517 - val_loss: 0.4530 - val_accuracy: 0.8919\n",
            "Epoch 149/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.5605 - accuracy: 0.9103 - val_loss: 0.6536 - val_accuracy: 0.8919\n",
            "Epoch 150/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4796 - accuracy: 0.9241 - val_loss: 0.7762 - val_accuracy: 0.8649\n",
            "Epoch 151/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4622 - accuracy: 0.9448 - val_loss: 0.3272 - val_accuracy: 1.0000\n",
            "Epoch 152/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3793 - accuracy: 0.9724 - val_loss: 0.8776 - val_accuracy: 0.7568\n",
            "Epoch 153/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.5141 - accuracy: 0.9103 - val_loss: 0.3270 - val_accuracy: 0.9730\n",
            "Epoch 154/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.3314 - accuracy: 0.9724 - val_loss: 0.4759 - val_accuracy: 0.8919\n",
            "Epoch 155/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2802 - accuracy: 0.9862 - val_loss: 0.2541 - val_accuracy: 1.0000\n",
            "Epoch 156/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2271 - accuracy: 1.0000 - val_loss: 0.3038 - val_accuracy: 0.9189\n",
            "Epoch 157/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.2043 - accuracy: 0.9931 - val_loss: 0.3993 - val_accuracy: 0.9189\n",
            "Epoch 158/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1859 - accuracy: 1.0000 - val_loss: 0.3044 - val_accuracy: 0.9459\n",
            "Epoch 159/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1756 - accuracy: 0.9931 - val_loss: 0.2802 - val_accuracy: 0.9189\n",
            "Epoch 160/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1838 - accuracy: 0.9931 - val_loss: 0.2958 - val_accuracy: 0.9189\n",
            "Epoch 161/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1549 - accuracy: 1.0000 - val_loss: 0.2847 - val_accuracy: 0.9459\n",
            "Epoch 162/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1518 - accuracy: 1.0000 - val_loss: 0.3765 - val_accuracy: 0.9189\n",
            "Epoch 163/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1448 - accuracy: 1.0000 - val_loss: 0.3806 - val_accuracy: 0.8919\n",
            "Epoch 164/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1346 - accuracy: 1.0000 - val_loss: 0.2899 - val_accuracy: 0.9189\n",
            "Epoch 165/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1474 - accuracy: 0.9931 - val_loss: 0.4313 - val_accuracy: 0.9189\n",
            "Epoch 166/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1320 - accuracy: 1.0000 - val_loss: 0.2023 - val_accuracy: 0.9459\n",
            "Epoch 167/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1409 - accuracy: 0.9931 - val_loss: 0.3168 - val_accuracy: 0.9189\n",
            "Epoch 168/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1355 - accuracy: 1.0000 - val_loss: 0.2557 - val_accuracy: 0.9189\n",
            "Epoch 169/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1492 - accuracy: 0.9931 - val_loss: 0.2708 - val_accuracy: 0.9189\n",
            "Epoch 170/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1717 - accuracy: 0.9931 - val_loss: 0.4079 - val_accuracy: 0.8919\n",
            "Epoch 171/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1474 - accuracy: 1.0000 - val_loss: 0.1676 - val_accuracy: 0.9730\n",
            "Epoch 172/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1459 - accuracy: 1.0000 - val_loss: 0.2129 - val_accuracy: 0.9730\n",
            "Epoch 173/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1322 - accuracy: 1.0000 - val_loss: 0.1998 - val_accuracy: 0.9730\n",
            "Epoch 174/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1360 - accuracy: 1.0000 - val_loss: 0.1646 - val_accuracy: 0.9730\n",
            "Epoch 175/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1275 - accuracy: 1.0000 - val_loss: 0.1792 - val_accuracy: 0.9730\n",
            "Epoch 176/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1311 - accuracy: 0.9931 - val_loss: 0.2842 - val_accuracy: 0.9189\n",
            "Epoch 177/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1298 - accuracy: 1.0000 - val_loss: 0.1971 - val_accuracy: 0.9730\n",
            "Epoch 178/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1258 - accuracy: 1.0000 - val_loss: 0.1869 - val_accuracy: 0.9730\n",
            "Epoch 179/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1619 - accuracy: 0.9793 - val_loss: 0.3047 - val_accuracy: 0.9189\n",
            "Epoch 180/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1569 - accuracy: 1.0000 - val_loss: 0.2226 - val_accuracy: 0.9459\n",
            "Epoch 181/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1334 - accuracy: 1.0000 - val_loss: 0.1843 - val_accuracy: 0.9730\n",
            "Epoch 182/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1352 - accuracy: 0.9931 - val_loss: 0.2164 - val_accuracy: 0.9459\n",
            "Epoch 183/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1297 - accuracy: 1.0000 - val_loss: 0.2030 - val_accuracy: 0.9459\n",
            "Epoch 184/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1395 - accuracy: 0.9862 - val_loss: 0.2106 - val_accuracy: 0.9459\n",
            "Epoch 185/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1301 - accuracy: 1.0000 - val_loss: 0.2873 - val_accuracy: 0.8919\n",
            "Epoch 186/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1250 - accuracy: 0.9931 - val_loss: 0.2401 - val_accuracy: 0.8919\n",
            "Epoch 187/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1301 - accuracy: 0.9931 - val_loss: 0.3982 - val_accuracy: 0.8919\n",
            "Epoch 188/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1205 - accuracy: 1.0000 - val_loss: 0.1926 - val_accuracy: 0.9730\n",
            "Epoch 189/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1174 - accuracy: 1.0000 - val_loss: 0.1942 - val_accuracy: 0.9459\n",
            "Epoch 190/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1219 - accuracy: 1.0000 - val_loss: 0.1732 - val_accuracy: 0.9459\n",
            "Epoch 191/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1254 - accuracy: 0.9931 - val_loss: 0.4151 - val_accuracy: 0.8919\n",
            "Epoch 192/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1275 - accuracy: 1.0000 - val_loss: 0.2399 - val_accuracy: 0.8919\n",
            "Epoch 193/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1362 - accuracy: 0.9931 - val_loss: 0.4725 - val_accuracy: 0.8919\n",
            "Epoch 194/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1265 - accuracy: 1.0000 - val_loss: 0.2188 - val_accuracy: 0.9459\n",
            "Epoch 195/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1126 - accuracy: 1.0000 - val_loss: 0.1621 - val_accuracy: 0.9730\n",
            "Epoch 196/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1287 - accuracy: 0.9931 - val_loss: 0.1750 - val_accuracy: 0.9730\n",
            "Epoch 197/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1265 - accuracy: 0.9931 - val_loss: 0.3024 - val_accuracy: 0.8919\n",
            "Epoch 198/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1412 - accuracy: 1.0000 - val_loss: 0.1912 - val_accuracy: 0.9459\n",
            "Epoch 199/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1391 - accuracy: 1.0000 - val_loss: 0.2258 - val_accuracy: 0.9459\n",
            "Epoch 200/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1285 - accuracy: 1.0000 - val_loss: 0.1966 - val_accuracy: 0.9730\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.subplot(1, 2, 1)\n",
        "plt.title(\"Loss\")\n",
        "plt.plot(history.history[\"loss\"])\n",
        "plt.plot(history.history[\"val_loss\"])\n",
        "plt.yscale('log')\n",
        "plt.legend(['loss', 'val_loss'])\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.title(\"Accuracy\")\n",
        "plt.plot(history.history[\"accuracy\"])\n",
        "plt.plot(history.history[\"val_accuracy\"])\n",
        "plt.legend(['accuracy', 'val_accuracy'])\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "eq0RjzX8A_3h",
        "outputId": "a697a0c3-e3ac-48c7-851f-227b5b995370"
      },
      "execution_count": 462,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAEICAYAAAC3Y/QeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOydd3wcxfn/388Vnbply7LlbuOKjY0NpocSSDDNhkDAkEIN5EsoCRASQgghhJBCfumkhw4Bh5DEgCmhxXRsjAu2wbhbcq/quja/P2b3bu90J52kO53uNO/XS6+73Z3dnTvtfeaZZ555RpRSGAwGg6Fv4cp2BQwGg8HQ8xjxNxgMhj6IEX+DwWDogxjxNxgMhj6IEX+DwWDogxjxNxgMhj6IEX+DwWDogxjx78WIyEYR+Uy262EwtIeIvCYi+0TEl+26GFLHiL/BYOgyIjIaOB5QwJwevK+np+6VrxjxzzFExCcivxKRrdbfr2yLS0QGisgzIrJfRPaKyOsi4rKOfVtEakWkXkQ+FpFTsvtJDHnCxcA7wAPAJfZOERkhIk+JyC4R2SMiv3Mcu1JEVlvP4ioROczar0RknKPcAyJyl/X+JBGpsZ7j7cD9ItLfet53WT2PZ0RkuOP8ASJyv/U72Sci/7b2fygisx3lvCKyW0RmZOxb6oUY8c89vgscDUwHDgWOBG6zjt0E1ABVwGDgVkCJyETgWuAIpVQZMAvY2LPVNuQpFwOPWn+zRGSwiLiBZ4BNwGhgGPA4gIicD9xhnVeO7i3sSfFe1cAAYBRwFVq/7re2RwLNwO8c5R8GioEpwCDgl9b+h4AvOcqdAWxTSn2QYj3yAtN1yj2+CFynlNoJICI/AP4EfA8IAEOAUUqptcDrVpkQ4AMmi8gupdTGbFTckF+IyKfQwjtPKbVbRNYBX0D3BIYCNyulglbxN6zXrwA/U0otsrbXduKWYeD7SqlWa7sZ+KejPj8CXrXeDwFOByqVUvusIv+zXh8Bvici5UqpOuDL6IaiT2Es/9xjKNqistlk7QO4B/1jelFE1ovILQBWQ/ANtMW1U0QeF5GhGAzd4xLgRaXUbmv7MWvfCGCTQ/idjADWdfF+u5RSLfaGiBSLyJ9EZJOI1AELgQqr5zEC2OsQ/ghKqa3Am8B5IlKBbiQe7WKdchYj/rnHVrS1ZTPS2odSql4pdZNS6iB0d/pG27evlHpMKWVbagr4ac9W25BPiEgRcAFwoohst/zwN6BdkTuAkUkGZbcAY5NctgntprGpjjsen4L4JmAicJRSqhw4wa6edZ8Blrgn4kG06+d84G2lVG2ScnmLEf/ej1dECu0/4O/AbSJSJSIDgdvR3VhE5CwRGSciAhwAQkBYRCaKyMnWwHALursczs7HMeQJ56Cfr8no8afpwMFoV+M5wDbgJyJSYj27x1nn/RX4pogcLppxImIbM0uBL4iIW0ROA07soA5l6Gd5v4gMAL5vH1BKbQOeA35vDQx7ReQEx7n/Bg4Dvo4eA+hzGPHv/SxAP+D2XyGwGFgOrACWAHdZZccDLwENwNvA75VSr6L9/T8BdgPb0YNf3+m5j2DIQy4B7ldKbVZKbbf/0AOuFwGzgXHAZnQQwlwApdQ/gB+hXUT1aBEeYF3z69Z5+9FjW//uoA6/AorQz/U7wPNxx7+MHgf7CNiJdn1i1cMeLxgDPNXJz54XiFnMxWAw9EVE5HZgglLqSx0WzkNMtI/BYOhzWG6iK9C9gz6JcfsYDIY+hYhciR4Qfk4ptTDb9ckWxu1jMBgMfRBj+RsMBkMfpFf7/AcOHKhGjx6d7WoY8pT3339/t1Kqqqfva55rQyZJ9bnu1eI/evRoFi9enO1qGPIUEdnUcan0Y55rQyZJ9bk2bh+DwWDogxjxNxgMhj6IEX+DwWDog/Rqn7+hfQKBADU1NbS0tHRcuA9TWFjI8OHD8Xq92a6KwdBrMOKfw9TU1FBWVsbo0aPRudwM8Sil2LNnDzU1NYwZMybb1TEYeg3G7ZPDtLS0UFlZaYS/HUSEysrKLveOROQ+EdkpIh8mOS4i8hsRWSsiy+0lCQ2G3o4R/xzHCH/HdPM7egA4rZ3jp6OzqY5HLy34h+7czGDoKXLO7bO30c8Db23k9EOqOXhIebarY8hzlFILRWR0O0XOBh5SOk/KOyJSISJDrHzyPccnL0HlQVC/HYr6w6CDUz931xpo2A5jTkh8/OPnoHoalA+FpY/C1Atg1b9h4umw/jUYcTSUOuYUNeyEzW9Td9AZvLhyB+cdNoz1uxvZsreJkyYO4q21uxngamRS02I45LzYe21YCKXVqIHj+cf7NZwyaRCVpT4AgqEw8xbXMKDEy9qdDUweWs7ymgPMPWIEFUUF3PfmBkZVFnPWtNhF6pr9If6ztJbPHz4cj1vbuzvrWnj9k90EW+oZsu1ljj/3a8j+jbBvI4w9OfH3EA7B0sfg0IugeR/r3v8vm6s/w44DLZx16FAefGsjrYEQPq+bCYPL8LiF3fWtnDqlmofe2kggpJfQOKiqlN0NrfQr8uIPhQkEw1SW+qgo9hIIhRlbVcpTS2pxu4TJlsat3lbH5KHljKosYf6yraAUZx06lAmDy1L/P8eRc+Lf0BLkNy9/wqgBxUb8ewGlpaU0NDRkuxrZZBg6SZhNjbUvRvxF5Cp0z4CRI0emtwZKwaPnQUEZ+Ov1vjsOpH7+vUckPycchr9fCP1GwKy74T/XwMY3YdljcNpP4flv64bh/16PnvP3C6H2fX4y4RkeW17HuEGlnPv7NwkrWH7HqXzhr+9ylftpbvX+HcaeAkWOxbYenA3AW19ax7eeXM4pkwbxt0t1/V5ctYNb/7WiTRVr9zUzsbqMe174GIDDR/VnSL+iyPHH3tvMD59ZRZM/xOWf0uM+1zy2hEUb9/ETz585wfMa2yZOYcg/z2n/u1t8Hyz4JvgbYcU8xta+z+da/kwdpTz1QS3vbdiLiP53OPnH+zVJjyVixsgKPti8v83+Ao+LiYPLWFF7ABE4eEh5t8Q/59w+hQW6ys2BUJZrYjCkjlLqz0qpmUqpmVVVac4o0WKJlS38aeLj7fVc84Al6ge2QNAaN9ljrbneuEu/7l0fOaehNUjz1lUA7N+hJ5qec68WfoBfvLgGgCGyV+8IBRLe++G39bkvf7STuxesjtQnEfOXbeWBtzYyqEz3EE685zWueXQJp//6dZZu2c+BJj8Adz6zihufWMpXH17Moo16ad8q0d+dv35Px19Io7VUcfM+wns3AlCA1qH3NuzlqDED2PDjMykpcMec9t6GvZw8aRAbfnwmb96SpFfh4IPN+/naSWOZMLg0Zr8/GGZF7QFunjWRDT8+k9OnDum4zu2Qc5Z/kVd/sS1G/HsVSim+9a1v8dxzzyEi3HbbbcydO5dt27Yxd+5c6urqCAaD/OEPf+DYY4/liiuuYPHixYgIl19+OTfccEO2P0JXqUUvFm4z3NrXc9SnycOkFFjjIy2BEF99eDHNe2r02nFAY9hLCYDf6uk1WYKpoiuCvrV2N8eGFQj4mnYC/WNuMW+x7iRV2+KvQviDYYLhMMUFUTl6fuV2Tp08mGU1+/nL6+v54lEjeWHldgBu+MwEHnx7I3sb/ZwyaRAvf7STmn3N/GrudNbvauA3r6zl2RX6O3luxTZ21EUH+5/6IPqvmTtzBIM2l0Md+FuaY+rZEgjhEqHA47CPlaU54iKooACYPKiAo2ZMZNW2Oq6wehV/v+ponv9wO/5gmIpiLx9tr+fqk/SyxcMqivjBnCm0BkPcveAjAG4/azJ3PqMbzH5FXk6eNIjLjhvDuYcNY97iGkTgczOGsWDFdmr3NfOlo5xLeHednBP/Qkv8m/1G/J384OmVrNpal9ZrTh5azvdnT0mp7FNPPcXSpUtZtmwZu3fv5ogjjuCEE07gscceY9asWXz3u98lFArR1NTE0qVLqa2t5cMPdQDN/v1tu7g5xHzgWhF5HDgKONDj/v46S9BcHggHu36dQBMUlABw7u/fYuOeJsaKFsWgcvHdZ9byK2hX/Pc2+iPvPU3b0OurR2nyhygv9FAd1pY34SDfn7+SRRv38sLXj8dpM9925mTcbuFTP32FE+95DdCC/fXPjOex93TP4MSJVdS3BFm3q4HTp1bj87j5zStrI9dYVrOf1mCYY8dWMqyiiH+8XxM59r3Zk/E/0Q/qIBCIjQab8v0XmDyknKev+1R0p/05xUUgLBQAv/n8wVSMHBdz7rThFUwbnmzdeLjk2NE0+6Pif+mxo3EJ3PH0Kn5z0QxOnKB7hlVlPm49Izp2M6k6vW7unBN/r9uF1y3G7dPLeOONN7joootwu90MHjyYE088kUWLFnHEEUdw+eWXEwgEOOecc5g+fToHHXQQ69ev57rrruPMM8/k1FNPzXb1kyIifwdOAgaKSA16kXAvgFLqj+g1ls8A1gJNwGU9Xsk6q60pKIWWbjSkrfUR8V+1TRsSpWjxD7s87G4KaXPX3whA474duifgEP+Ne5oQtI9niOzln1cfw4ASH7sbWvnlf9fw1ro9fHrSIIas1pb/qtp9vL1uNxv3NPHc8s2cZV3nyf87hpGVxQCMqyrlk50NlBV6+NZpsY3JoLJCfveFGdS3BvF5Yt0tM0f158PaOjxu4fRDqhlUVhhzvNTn4YBX7wu0tkb2t/gDhMKKFbXaJfTy6h0cOqKCgfbndLnwh6EEqPB2rbEtcriGXC7h4mNGc8iwfswcPaCds9JLzok/aOvfiH8sqVroPc0JJ5zAwoULefbZZ7n00ku58cYbufjii1m2bBkvvPACf/zjH5k3bx733XdftquaEKXURR0cV8A1PVSdxNhuH3dB967T2gBlsb3qEtEWscvtpaLQBWEi4r91aw3jXegoGIttu/dSIlpIjxrYyuGjtJiNGVjCtOEVvLVuDwdVFlIlupG6+uH32KSqAfjbq6sj4u8UwQmDy/hkZwOXHjs6EvljU92vkEHlhQxy7Pvh2VP48XMf8YWjRnLjvGUATBxcxnHjBvLrlz/B4xIuOEJ76txe/Z0F/VG3z+raqP+/2R/iigcXc8iwcp6ZGHX7tNqaH+j67PqjDxpAWaGede5ySerCb48adzPMO+cGfEH7/Y3Pv3dx/PHH88QTTxAKhdi1axcLFy7kyCOPZNOmTQwePJgrr7ySr3zlKyxZsoTdu3cTDoc577zzuOuuu1iyZEm2q58b1G2Du4fB1g90aOePR+i/1/+fPt7iiFJ57tvw45Gw9mXYuRp+WAWb34E7B+rzAZ79Jjz+xeg5rXX8ev7bqB8NYaZ8xG8vmkGZZfm73F4GFFlyYQ389hdrAFaFYfdauLOSsh3vRS53bOPL8LOx+r53VfONZWfxUsE3ueadk3CjrWj7deao/tTs3Buty09GwU/HwO+O5Nod3wNgxADdE+Dhc7mZhwCoLLEavPvPgJ9PgD8ez5dfP4VV14zgDGtAdJJs5uI3P8v4+6awcdTdrK2+jbs/NxX++RVKP3xEf4SW6GDyik27+Z331zxXcAu+n4/mTs/9fFhbF+3hvHQH1ViDv8HYsYKEbFsG94yL/r/+dAL8YgqPh27mL8fV62MtDpftkofgV9NiQ4Pe+CX8aCgse0IPuN89FFY/0/G92yEnLf+iArfx+fcyPve5z/H2229z6KGHIiL87Gc/o7q6mgcffJB77rkHr9dLaWkpDz30ELW1tVx22WWEw/rH9OMf/zjLtc8RPl6g/e2L74OtS6E1bownFHVdsPoZaD0AO1fpBiDkh/nXQzgA7/0VzrkXFv0l5nTVWsfaxa9T7Grlq55nGFx5BSWW+IvHS3mBQGO0fH9swVSw/HEIBznhwHxsx70EmvQ4wvO3QLCZwmAz41yA46frssT/2pPHcdsDH0cP2O6r5r0czMdcfMxPmW3H7697mc8D60+6leH9i3Q46qY39bGGHfp110cUDp7Cby6awcB1G3EttyKTdjgayBX/iLwVR6TU88u38Jj7Xb3hhyNcVr0c7q0IqVj+O1fryKjpX4Jdq6H2fb2/rgYW3KyP7VgJo47R++dfp19b66Cwn/WZX4VAI2xdAmXV+nst7N4YQO6Jf6CZw+VjXM1js10TA0Ri/EWEe+65h3vuuSfm+CWXXMIll1zS5jxj7XeBVkugClKI7W7cqV9TGQB2eSEcoLHuAK1By68PjKosodQa8BWXR4u/A7c4LFMrZLNYrAHfynHRkFBJ7mDwWOJ/+Kj+FBIdLI6ZswDcefYhbc791mmT9JvWBCGgAV3vOYcOBb8PlqOF1O4dhWONR6f4r926JxLhFEMi8U/F8g806deTvwvLHo+Kv7Puzl5bUX9o3qd7erb42669QFP0fVnsZLbOkntun7qt/KLh24xrWJTtmhgMPYsdZeMrbb8caEsfUhP/sBbutTXbsOX9iNH96Vfk5ZsnDdM7XF5KCpL7mGv3ahHr57VEdeCE6MFAcoG03T5lhd5Y8S+pBFL0abcj/jHHy4dF94X8McVdgWiXZrDsiznmsbsqXbX87TLeIvDFNdx23eq3RvcVVrTdZw/qB1qgztpf3r04/9wTf4814NONgRaDISdptsMjO+Hy7ETZJ9/+CJ8lwBVF2vwvtyx/VJiydjJiv7hCh1CWua3Gxin++7ckOEPjJoTHpUU+Rvx9ZeBJZH4nwJ9ghnnQoQ+tDbr3UeKYXBdsjSnuCUSvMdG3N+aYF/2ZQqEEDWkqlr9dxpNA/O1Gp84RHVzUP3Zfa320FxRs1pa/r18kMqur5KD4Ww9E3D/PYMh7nGKQKk7L3xoTCKkwN85b2qZoGc2USZyYtUZFp6SdYCLbgi91Wb/LKkdIZjszj92EqSzVFy4Ux2zfgjLwJhD/RPkRElr+LbHHfWWxwhtn+XuCUfE/vF/sWIpHdAPa0Bx7Tpv7JCPQAog2XOPF38Zp5RfFWf7OhsG2/Ltp9UMOi7+EjPgb+hi2GGxbptMtOPEWJz4nHIwOBFt+5QM1H/POkmU0uGIHDKdVuTnlIOs6u9fAB4/CdiuTddMehjV/krRqk1ybASgJWb7rAamNyZ13aBXzTtPi+r1ZjvUWfGXaUrap3w47VsHal6L7ahbrsYY1z7e98M6V0R6Hv0E3Jk7hXf9aTPGiYFTwT2+aH3OswLL89zcmEPrWOtj0lh50Xv+/aOO0+xM4YE0oCzZr3RLRczESsXUprH5an29fY/ED2n3lbBgObIGPnoGy7ot/jw34ishBwHeBfkqpz3f5Qkb8DX2VBmsQd8s7bY+VDoZ9G9ruDwe12wMibqMBe97nrcL32eMdSakjYuj0CaVQWKTT1O1dB//5WsylJm16NGnVjrQiYooC+0HcMHB8Sh/pSw33w/xFMPgVJlY65OjQC2GPo7F58baY6BwA/noKzPgyfPCw3q46WEfTeEtg5b/03x0HtEDHW/5PXRlzqdJgdHJcRWBn5H1ICR5L/OuaEmjOaz/Wf4ddAksehAv/DpPOgN/N1MfvOKCtdbsXk8zy3/EhPPEl+OrrUZdVXQ2smh+N5+83AnbpWcEMmpz4Op2gW5Z/soUuROQ0EfnYWuDiFgCl1Hql1BXduR8Abg8h3LhDxudv6GO05+4ZkGCVMm+xtkgT+cQBXLEzYgm1xt5j8tnw9eVwwrc6V09fGRQPgNt2wrQLrX3l8Kkb9fvDLoFLntbva6zAjdb6qAvl2sVwyLmxlr8tevHYIZ4AFz0G39vd1l3UWq8HyZNZ3YBPxbm75j4Ct+3kwdAsvNaA7/6mdjRnw//06/7NbY8Fm6OfJZH4z30EPn+/ft+8V1v71VOj23YDXWpNZXP74NS7ktclRbrr9nmAuIUuRMQN3Ite5GIycJGIdL+ZchByFeAOG8vf0IdQqn3xr4hL9uXy6hm/4WDb+QCRa8YNBocC0V4C6HDN/qOi4YapYguc08ftLY4OZLoL2s5GVuHowKjPckd5HGX2JujVAPibou8LK8DtjW00QH8mX1m7A6Q+FSfsJVXg8dG/rASv2G6fdjSn0ZoVHI77DqFjy7/fcKgcG61rsEVb+fa2fb0SS/wrx4Gr+x77bl1BKbUQ2Bu3+0hgrWXp+4HH0QtepISIXCUii0Vk8a5duxKW0eLvR6WSHNvQaygtTW55bdy4kUMOaRvLbbDwNwLtPO/xouLxRRO9JWk0JD4MNNga21CUW3HkiQZe28NZl4j4F8YKvsT1OpyWf+R+jlDPZL0X52ezLftEln9BabvzDbzENYSWe/lzM8fgEz2YHQy1EzllD2rXb4/Nshps1WJuN0jO3oe9r2xo9HtqrdeWf0GprkNrnd4nrmjjmUqobwpkYsA34eIWIlIpIn8EZojId5KdnEre85DLR4EK0BpMEHdrMOQjycTPxhtn7bo8DvFPcm4by7819j5dnUTkFLiIUMXF7Me7nFobYkMiU8URnx/pKbjiYlL9DdHeRKrY36fbi6gQpQUSiWhql/pt0Th8ezvQHG2QnL0PX5n+H5VURSfu+S3L31uoj/sbotFK3nZcR12gxwZ8lVJ7gP9Lx7XCbh8+8dPkD0VSPPd5nrsFtrdd5ahbVE+F03+S9PAtt9zCiBEjuOYandfsjjvuwOPx8Oqrr7Jv3z4CgQB33XUXZ5+dcscP0AvTX3311SxevBiPx8MvfvELPv3pT7Ny5Uouu+wy/H4/4XCYf/7znwwdOpQLLriAmpoaQqEQ3/ve95g7d263PnavpKPwzriY+Naw4HN5dJx/knNdbSx/f2xZO5ywuZOZQmMsf0t04+cbtBF/y/IXl3bddIf4z2X7/DuD/X1adaksdOFqTsHTULct1vKv2xZr+TuTsflKdW/I5XJY/nX6e/AU6Ua0tV6XKXCIfztjF50hE+Kf8cUtwp5CfARobA0yoL3gY0NGmTt3Lt/4xjci4j9v3jxeeOEFrr/+esrLy9m9ezdHH300c+bM6dQi6vfeey8iwooVK/joo4849dRTWbNmDX/84x/5+te/zhe/+EX8fj+hUIgFCxYwdOhQnn32WQAOHOjE8oW9nT3r4LlvwQUPdyj+25rAGfzXHBR8LjeNLS0UttaTyESSeMv/kxdit20fc2fn1DiF1haqcCAq6rZLysmeT2DRX7XQdTNbpT1jGdCJ6+xon85kPbWF1upFtPhbInmI2mXnKvjXV6Pb/7pKDwKP+0zbsr4yKLbqZH8nrfW6B2Rb/q0N4PbETnpLk9snE+K/CBgvImPQon8h8IW03sHjoxA/Da1dy6Wdl7RjoWeKGTNmsHPnTrZu3cquXbvo378/1dXV3HDDDSxcuBCXy0VtbS07duyguro65eu+8cYbXHedTm41adIkRo0axZo1azjmmGP40Y9+RE1NDeeeey7jx49n6tSp3HTTTXz729/mrLPO4vjjj8/Ux+15XrhVx7Wvfy3qLjjj53oRlUCz9sk//x1QIX6zsIa7v/YqTY9dTEnjFsLiApebl1fWcparKWGmBFe8+NucepcWIdvnf8w1sPBnyet59DVQMhBe/ZG2uosHRo/ZFm04CNO/qOPfT7hZ+8adrHtFv04+p8OvpQ0Hz4HxjjUhnL2Mj56J1mPm5bqB27Cw42vGWf4tLa24vAks/8lnw5BDoXaJ7iFtekPvH3MC9B8TnZfg7JnN/jX0H62XhbQbJBFdx5YDegKat9gS/3pdB19ptEFKdeZzB3Q31PPvwNvARBGpEZErlFJB4FrgBWA1ME8ptbKT150tIn9OZsWJw/I3ZJfzzz+fJ598kieeeIK5c+fy6KOPsmvXLt5//32WLl3K4MGDaWlJT1juF77wBebPn09RURFnnHEGr7zyChMmTGDJkiVMnTqV2267jTvvvDMt97JJFLYcd3yUiLwsIstF5DURGZ62m9vWcTgY9cUPPwJOugU++wM46qsw7QIAAnj4145B/KT+dABCuFEuD4X4cYlil1S2vXz8ICfo+QLHXgefvjVqgRdVwOn3tC0Lundw2t1w/I26bhA7+9S2UsNBbc2e/hN9vXi3j70O8GldyPA648tw2Jej24nyGRWUQkExnPnL1K7p8PmDnujljv++pl4AFzwEx98EFz4Kk86MHpv9a5jzG5h0Vuz1AA6/FA46CaZ+HibPie73lUXXCfbYPv/6qM/fTm0T32vqIt2N9rlIKTVEKeVVSg1XSv3N2r9AKTVBKTVWKfWjLlz3aaXUVf36JQ4xE28hPglQb8Q/68ydO5fHH3+cJ598kvPPP58DBw4waNAgvF4vr776Kps2ber0NY8//ngefVRPKFqzZg2bN29m4sSJrF+/noMOOojrr7+es88+m+XLl7N161aKi4v50pe+xM0335zWbKEphi3/HHhIKTUNuBNIX37qiPgHom6fJIN9Sgk3zltGY1D/pEO4CCgXJeiGd11oUJtzXIkSlSWzKpP54W1BgujYgHOg2K5vfF6cePEHbQUXt22kOiQ+1UGiReHtsYdUxxPscpbb555zJzNhYOxCMm0SvTnrYc/AtfelkmCvoEyndwbdWNg+fztaye7RpEn8cy+lM+DyGsu/tzBlyhTq6+sZNmwYQ4YM4Ytf/CKzZ89m6tSpzJw5k0mTJnX6ml/72te4+uqrmTp1Kh6PhwceeACfz8e8efN4+OGH8Xq9VFdXc+utt7Jo0SJuvvlmXC4XXq+XP/zhD+n8eJGwZQBrnd6zgVWOMpMBa/YSrwL/TtvdbQFyDtrGib9CxXh0gtZPujEAe3Y1U2KFVG4MD+Zo1+qYcxNa/vFRQ/F1abPf4UdvtqK+nSJY4HD7OIkP9QQtmMn8/WVDki9UHx+VlEho7R6Ix9f2WHtYn++kcRWw2gvOhJ/xbjNnPbxFsftSGTT3lUVncXucPn+vbrzsz9WXxd9dYMS/N7FiRTTKaODAgbz99tsJy9m5/xMxevToyILuhYWF3H///W3K3HLLLdxyS6znZdasWcyaNasr1U6FRGHLR8WVWQacC/wa+BxQJiKVVnRb97B/5KHkln8wpHDKst/6SYdwEcRNqWX520slOvEkEv9kln98+CToiJQY8beU0Zk6OeLzj7PGEwlYeZyIOxuCgeMTi7/bp2cTO0ko/lY9OrvUpd3ohQJtey9tLP8EobH2vuZ9bWTKpmQAACAASURBVI8lquNOq4G20z9HfP5l0c/V3Wgoi16Z2K0jn7+7oBgffupbjPgbss43gRNF5APgRHSQQxtVTWXyYhvi3T7ibiPO8WtZB624nhBuQrgYUqhFt0YNJJ6EceudsfwL+8XOwrUzZZYl8fk7SeT2aS9ZWfwMZpvyBL2FZD5/6Lzlb/8PtrwD++NcmPHiX5YgqMH+TCmJf6lefQ2iln+w2YpWKnVY/nks/h35/D0FRRRKgMZWs5RjrrFixQqmT58e83fUUfHGdK+hw7BlpdRWpdS5SqkZ6MSFKKXa9PFTmbzYBqfl72+0ZqnGCt3OiukA1JVocTx6nBagiUMqOHTkQIoty78x4dJUCeiMz79iZDQcFGDsyfrVubyg14pSsgc+bZxuH3vxkgEHxZaxrwex6wM4SbTfOfBq02XL3yo//zqoi4tYH3lsXFnrOxpyaHSf3SAcdFLH9yodHH1fXBnN5WMfq56m3w+d3vG1UiAn3T4Rn7/fWP5KqU7F0GebqVOnsnRp21zymaQbaUA6DFsWkYHAXqVUGPgOcF83qhqL0+cf8sda2RZvlJ3JZa0lzJg4A5ZtpaxUW+4utwc83kjagRYKeOrkVzl35mh481fw5q9jL+Qt0bNlk1r+CUTz7N/FLpBy4WOxyxGCnsB042ooinPNOC3/M+7R7pGhh8WWOek7cNjFuqEoGQjT5urvJNiqZyMnm7V7zh9g1HHw7I3Rfbb4O91NN6zUOZM+eAT+lyRUOpmL5cRvw9FXt91/05rYOHxfKdywKvZ7SsbJ39ONpLcYhh0GI46EgRMBBcNm6v//9UsTJ/HrAjkp/nh8Otqnj7t9CgsL2bNnD5WVlTnVAPQkSin27NlDYWHnY6OVUkERscOW3cB9SqmVInInsFgpNR84CfixiChgIXBN2iofsfz92vqPE+Db/r2CR97ZTFXZSEZX6jz8SqxzXO6YXDYtqgBVMkj7xxO5UAqKtfgn9fknkIqiAbH+dm9R4sYjkS/cKf5FA2D0pxKXqRgZ3S4b3LZMIjy+aKI0G1v8nb+TflZUboJGNUIy8R8wNvHgdKI69hvWdl8ifKUwxjFPxe2NLuoeuW96hB9yVvwLKcRPY0uCkK4+xPDhw6mpqSFlH3IfpbCwkOHDuxZ+r5RaACyI23e74/2TwJPdqmAybIEMtmi/f5wAP/KOTh9c4HbhdWuhj6S7snP7WLRSEB0fSOT3LijRYYadsfzbSZTWIU63T5oGMGOIzw/U3sSo9qJnkvnXE41Z5Bg5Kv764W1tTWH9zDzG6/UyZkz6LAFDLyXQrK3/OAGuKvOxq76VuUeM4Nhxlfy//8K0YaV6amWc+Lfg5ZBh1hiaO4H42775ZEKYSKC7k1bYeZ9MiH98Zs/2esaJwk5tko0RdKfh6yX0SvEXkdnA7HHjxiUuYE119zclyVNuMOQD9qSeYIvl9mkrknMOHcq1nx6HyyWs/MEsSmpe1wdc7hiBfebGz1JUZQ2sJnJz2OkjkolaIgu4PdHsCKfl3NlB2JSu3wlpa6+sO8mxNMXaZ5Ne2Xx1FO1jj4KHG3YmPm4w5AP2TNVAsw7zc4i/UooDzQGGVBTicmmrtsTniU48cnliBLaoyDEImdDyt7NOJpGEhJZ/N8Tf2XBkQkhTmVEbuX87n8O4fXoZVkiUq2FHzkW7GAwpYwtYsEW7fRxC1BII4w+GqSiKs5pHHQdjT4FZ1tqyNk43SCIht0W/M+LfHdeH02WUCcu/6mCYeKaOEnIOGoNeTtI5cOr8HEdcCSMcocfOuh1+GbxvTT7MA8s/Nz+BJf79Qvuobw1SXpgBn6HBkG3CDss/zu2zv1lPqKoojnv2vUXw5af0e6dAOQdAEw34RiYQJbFoEw74psn6zciAb4Fe0zcRn/l+7LbzezrjntjxAafbZ/avouKfrs+eRXql26dDLPGvkv3srDMLuRvylHZ8/geadcPQr6gd4bRFzeWJFbFEbh/7Xkl9/gnsxHS5PrJtRTs/R7wXIVmvJA1r6Gab3PwEvjJC7kKq5AA768xC7oY8JcbnH2BbfYi31uqUv/ub9LGKdsXf+nm3CXtMIGi25Z/U7ZPmUM+Ort2TdCnUMzedJk56pfh3lNsHEcIlgxgk+9hRbyx/Q54S5/P/cEczX/jru4TDKmr5x7t9nNgCFR/26BDbSE5Q28WUbPwsoc8/TWNtmXD7dIZ2Qz2T1M24fTJDh9E+gKt8CNWyj9p9fTvW35DH2OIfaIZQMJK07ZRf/I+rH3kfgP7F7VjNtvjHW/4O8Rf7vZ2xMpmoZdLSzbb4t+fCsesW38sxln/2cFeNZ6KrlnW7GrNdFYMhMzjEX4UDBKz4jA27GxlbVcodsyczpF8KM1fjLX/nbNfqQ/Tr8Jn6NT65mk0mXTNpylLZ9fu3F+dvfe5Rx8Wdk/uWf+42X4Om0J9H2LV9M5CeLHcGQ6/C9vn7G1EuDwHHMuxHjhnApcd1MLvbFrX41b/sCV2gk6d5fDD6eJhyDow5MfG1MmmdZ9vn354Lx+ODr7yi1xOIOSdn7eYIufsJBuvV9Ly7PyIc7nLWRoOh92Jb/v4GVChAUEVttXajfGxs67SgNHa/c9tdoBcbF9Fph5P58fPa7dOBFT/88Ng01WDcPlll0BQADgpvona/8fsb8hBb/FvrIdgaY/m3ie9PRDLL3xn2maqIZXIiZbYnaXZFyPPA7ZO74l9aRaCwkomyhU921me7NgZD+omkKFC4WusiPn+g7czeRCQT/0Rl+jJdceHkwffWK8W/w1BPu9zgKUx0beGTHcnXhjUYcpZQNGW5qGCM+Lcb4hk5ybJOvcXJy+SBBdttuiLkJtQzM6QS6gngGXIIE101rN3RfiNhMOQkccnJgg63T2o+f+vnnSxHPxjxh659B2aGb5YZNJlC/NRtW5vtmhjyFBE5TUQ+FpG1InJLguMjReRVEflARJaLyBlpu3k4GBMJE+P2ScXyD1sru7Rr+XfC6q2eCkdelXr5XKErVrxx+2SZSp3vX+1eR8hE/BjSjIi4gXuB04HJwEUiMjmu2G3APGsB9wuB36etAuEgFPWPbAaUY8A3FZ9/oEm/xsf5O+mMiP3fG3qd2XzDuH1yEGudziHhbWzcYyZ7GdLOkcBapdR6pZQfeBw4O66MAuw4wH7A1rTdPRSIEf8gbgaV6aRsKbl9glbqk0SWvz3I2Vnhy0c3UVdcOHnwPeR236WkipC3hNHB7azeVsfYqtKOzzEYUmcYsMWxXQMcFVfmDuBFEbkOKAE+k+hCInIVcBXAyJEjExVpSzgUK/7i5amvHcvb6/ZQVJCC+NiWf6L1a73F4G/ovIjlgbujDV0K9cz97yG3LX8RpHIsY1w7WL3NLOloyAoXAQ8opYYDZwAPi7SNHVRK/VkpNVMpNbOqqiq1K4djLX+3x8vw/sWcP3NEaucHrPkviSx/u0HorIjlgbujDV35TGaGb/ZxVY5lvGcHq7eZWH9D2qkFnEo73Nrn5ApgHoBS6m2gEBiYlrvH+fwLfO347hMREf8E0T52g2Dn8U+VPHB3tKFL0T7G8s8+Aw6iOryTNVv3ZrsmhvxjETBeRMaISAF6QHd+XJnNwCkAInIwWvx3peXuoUBMHp5CX4JFWNqjuFK/liRoi+Jz1aRKtmfjZoI+OsO3VzZfIjIbmD1u3LiOCw8Yi5sQ7voa9jX66V+S5SRRhrxBKRUUkWuBFwA3cJ9SaqWI3AksVkrNB24C/iIiN6AHfy9VSqUn9Cwcisl46eus5T/rbhh5jP6L5/N/g7Uvx65l29Nc+Sqk6avqFl1x4eSB+6tXir9S6mng6ZkzZ17ZYWErBe1o0X7/Y8elp8dtMAAopRYAC+L23e54vwo4Lv68tBAOaAuzoBT8DRQXdVL8faUw/aLEx4r6w9TPd7+O3WHYYdm9v40Z8M1RrHDP0bKdVWbQ15BPWOv2Kst9U1zYSfE3pEaXfP65b/nnvviXVIGvH1N928ygryF/UApUCFweQkW6N1tc3E6aBkPX6VK0T+6PfeS++IvA0Okc7tlgwj0N+YOd18flpdU3AIAKM5yVGfLAhdMVcl/8AYYdxsjABjbv3Is/GM52bQyG7hMRfzeNHh3u2R+TwDAj5IELpyvkh/gPPQy3CjIuvJF1u0x6Z0MeEBF/D5uHzwFADZuZxQrlMZ2J9pl5eebq0cPkh/hbUQPTXOuM68eQHzjEv6bfYYxueQz30GnZrVO+0hm3z1m/hDvyoweWH+JfPgxVMogZbuP3N+QJdjpml4eGVt0QlPr6pm864xi3Tw4jggw7jMM9G1hjVvUy5AMRy99lxD/TmAHfHGfoYQwP17B1x85s18Rg6D7Kyrkjbhpbg4hAcSqZPA2dJw9m63aF/BH/YYfhQjGwfhWNrcGOyxsMvRk74Zrl9ikp8CB5EFveK8mDJRm7Qq/81Kku4B7DUGvQV9abiB9D7uMM9WwNGpdPj9C3GtdeKf6pLuAeQ0klgdJhTHZt4hPj9zfkOsoa8BW3tvx9vcg1ccFDcHF8ctMc54yfw9feznYtepS8MifcVeMYVVfL8zuN+BtyHIfl39Aa6l2W/+T4lSzzgCM7ziGZb/RKy7+ruAaMYbR7J2uN+BtynYjPX7t9SnqT+BvygrwSf/qPoULVsXXHjmzXxGDoHio64Gt8/oZMkF/iby1M4dq/MRIbbTB0BxE5TUQ+FpG1InJLguO/FJGl1t8aEdmflhvbbh9xU99ixN+QfvJM/HVu/zFs5f1N+7JcGUOuIyJu4F7gdGAycJGITHaWUUrdoJSarpSaDvwWeCotN4/M8HXT6DduH0P6yS/xHzgB5fJyiHsT767fk+3aGHKfI4G1Sqn1Sik/8DjQ3mjnRcDf03JnFfX5N/lDFPemaB9DXpBf4u8pQAZP5qjCGt7dYBZ0N3SbYcAWx3aNta8NIjIKGAO8kuT4VSKyWEQW79qVwvrulttHiRt/MIzPY8TfkF7yS/wBqqcxQa1nec0+mv2hbNfG0He4EHhSKZXwoVNK/VkpNVMpNbOqqqrjq1nRPgGlf6I+T/79VA3ZJf+eqCGHUhw8wMDQHpZsNn5/Q7eoBUY4todb+xJxIely+UDE8g8oPevUiL8h3eTfEzXkUACmujcYv7+huywCxovIGBEpQAt8m6mtIjIJ6A+kb4qo1YHwh4z4GzJD/j1Rg6eAuDipfDvvGL+/oRsopYLAtcALwGpgnlJqpYjcKSJzHEUvBB5XSqm03dyK9vFH3D7G529IL/kXP1ZQAgMncGTreu7Ysp+WQIhCr/nhGLqGUmoBsCBu3+1x23ek/ca22yesLf8CY/kb0kx+PlFjT2ZMwxI8wSbj9zfkJrbbxwz4GjJEfj5RE8/AHfZzons576wzfn9DDmJb/iFj+RsyQ34+USOPBm8xZ5Sv5/W1u7NdG4Oh81ihnq1he8DXuC4N6aVXin+XFnNx4vbCsMM50v0JS7fsZ2ddS3oraDBkGiuff0T8vb3yp2rIYXrlE9WlxVziGXk0gxrXUKyaeWGVyfJpyDEst4/fSvFT4O6VP1VDDpO/T9SYExAV4ozSNSwxSd4MuYbt9gkZy9+QGfL3iRp5DPjKmV24guU16cmyazD0GBHLX/9EjeVvSDf5+0S5vTDmBKYFl7N+dyP1LYFs18hgSB1lW/5602fmqhjSTP6KP8Cww6hoqaFMNfCeme1ryCWsGb4t9iQvY/kb0kx+P1FDpgNwhG8LL602g76GHMJy+xifvyFT5PcTNXQGIFxb9j9eWrWDcDh9qVcMhoxiuX1abLePmeRlSDP5/UQVD4ATvsmMhoVUN37EMjPwa8gVwrb4mwFfQ2bI/ydq6vkAjHNv4+XVO7NcGYMhRSy3T0tIUeBxISJZrpAh38h/8e8/GsTFUeX7eMfk9zfkCtYM3+ag4DNWvyED5P9T5fFBxUimFu5mec0BWgJmaccus/Zl+N892a5Fn0CFdGjyqm0NZrDXkBH6xlNVOY4pe19kenglizaakM8u88i58Opd2a5FjyIip4nIxyKyVkRuSVLmAhFZJSIrReSxdNy3NRAgpIR3N+4zSd0MGaFviP+0CwG4wvdf/rUk2RKsBkMsIuIG7gVOByYDF4nI5Lgy44HvAMcppaYA30jHvVUoRBAt+iadsyET9I2natr5cPBsDi+oYcGH28xsX0OqHAmsVUqtV0r5gceBs+PKXAncq5TaB6CUSktUQTgUJGz9PAeUFKTjkgZDDH1D/AGqD2WgvwZPoIFnl2/Ldm0MucEwYItju8ba52QCMEFE3hSRd0TktEQXEpGrRGSxiCzetWtXhzcOh4IRy7+6vLBLlTcY2qPviP+QQwGYNWAHTyze0kFhgyFlPMB44CTgIuAvIlIRX0gp9Wel1Eyl1MyqqqoOLxoKBQmjwzsHG/E3ZIC+I/4jjwKXh4urPuGDzfuZv2xrtmuUu4T7TMRULTDCsT3c2uekBpivlAoopTYAa9CNQbdQ4SAh6+c5uNzX3csZDG3oO+Jf2A9GHcvU3Qs4vKKBbzz+AdsONGe7VrmJNQGpD7AIGC8iY0SkALgQmB9X5t9oqx8RGYh2A63v7o3DoRAhy+0zyIi/IQP0HfEHOOZaXI27eGjQY4QV/Nes8NU1Qn1jwFwpFQSuBV4AVgPzlFIrReROEZljFXsB2CMiq4BXgZuVUt2eTahCUcu/yKRzNmQAT7Yr0KNMmAXHXEPJu3/ikdJmmhZWwjF/z3atco9w3xB/AKXUAmBB3L7bHe8VcKP1l777Otw+4weXpfPSBgPQ1yx/gElnQjjAp4LvcmrzApZsNks8dppQn3H7ZA0VChFSLv5y8UzGVpVmuzqGPKTvif/wI6Gof2TzmffXw75NEDD+/5TpQ5Z/trAt/6oy4+83ZIa+J/5uD4yfFdlcv3op6k/Hw5u/yWKlcoy+M+CbNcJhPeDrdZtsnobM0GPiLyIlIvKgiPxFRL7YU/dNyLHXwpgTARjeuAJpOQDbl2e1SjlFHxnwzSqW5W/y+BsyRbeeLBG5T0R2isiHcfsTJcM6F3hSKXUlMKfNxXqS6qnwhXkocXH+wE0AtO78JKtVyimM5Z9xVDhEGBdeI/6GDNHdJ+sBIGY6ezvJsIYTnSqf/VlC3kKkYhRTg7rdkr3rCQaMRZsSxvLPPOEQQVx4TVI3Q4bo1pOllFoIxOdITpYMqwbdAHT7vmmjaiKuRp2Hq4AAdz/+Ensb/VmuVA5gBnwzjj3ga3z+hkyRCRFOlgzrKeA8EfkD8HSykzubAKtbDJwQs/nJ6qXc9eyq6I7N78KG1zNbh1wkFDDWf6axB3xdvcNOMuQfPfZkKaUalVKXKaWuVko92k65TiXA6haDYlKzc3jJntjFXu47FR48K7N1yEWe/gb8cGC2a5G/rP8fw/a+oy1/4/YxZIhMPFmpJMPqHYw9Ofq+oIzPDq5jy95mdta1xJZTqmfr1dvZuVK/9p0Ebz1LzSIA7guebtw+hoyRCfFPJRlW76BscPR95VhGhLcyy/Uey1csjS3XuLtn65UrGNdPZmitJyQeng8fadw+hozR3VDPvwNvAxNFpEZErkiWDKuT150tIn8+cOBAd6qXGte8B195GSrHUb71df5U8Cs+899ZEA5Hitz8l/+wv8kMBLch2cBv4264ezjULO7Z+uQL/gZa3SV4XILLZSx/Q2bobrTPRUqpIUopr1JquFLqb9b+BUqpCUqpsUqpH3Xhuk8rpa7q169fd6qXGlUTYfhMGHl0zO53V0Tbq9ZdG0wOoEQks/w3vg7+enjLzJruEq31+F3FJsbfkFHM02Uz6cyYzb8veCXyfpjspnZ/S/wZBuP2yQytDbS4S4y/35BRjPjblA+F42+CI74CQGnDhsihftLAxt2N2apZ7yXkcIVteguWPZ69uuQTrXW0SBEFJtLHkEHM0+XklNvhsEsAmOiqiewup5FNezop/v4m2PJeOmvX+3D6/O8/Hf711ezVJY8INNezod6kdjBkll75dPXogG88JTp+/cvu/0Z2DSv08/GOepRSOv1zYwoLNf3na/C3z0J9Hq8Wliiv/xu/hH9c2uNVyRRJ8lQ5j18qIrtEZKn195Xu3nP3nt00UMS2A8bVaMgcvVL8e3TAN57iypjNHaqCceUhzjzwBKvfexl+PQ1+e1jH16l9X78GmjJQySwhcY9LKEEE1Et39EhVeoJ28lTF84RSarr199fu3rdQNdGgirp7GYOhXfrWMo6p4IkunvHf0OH48PMp135u8T5O+Lkn9IGW/R1fx54XJnk0aCcuUNEQ2A5z/OT+5LhInioAEbHzVK1q96xuUqyaacCIvyGz9ErLv7dwZeAm9lGGa/dHALjojJhZZZ1imeu0sfzzPtonWZ6qeM4TkeUi8qSIjEhwPPWcVeEQvnAzjRR2p94GQ4cY8U/EybfBmb9g4c2f5qRDx0V2h1UnrHhb9PNpvdvOin8+9XqS8zQwWik1Dfgv8GCiQinnrPI3AFBv3D6GDNMr3T4iMhuYPW7cuA7LZoQTbgZgJEBFNIGZSxyWv1Lti5st/vmU/jhe/PPpsyWmwzxVSinn6P9fgZ91646t9QA0UsS5MxJ1MgyG9NArLf+sDvjGU5ikDv4OQj9tf3eiQdGcJa6xy3+3T4d5qkRkiGNzDjqlSdcJtgIQkAJ+MXd6ty5lMLRHr7T8exXJrNumPeArbbv/+VvhnXuh1Eoal09un/gxjzwXf6VUUETsPFVu4D6l1EoRuRNYrJSaD1wvInOAIHpho0u7d1PdY1S90y4z5BFG/Dui/xj9OvYUWPdydH/Tbug/qm35d+7Vr/Y6t+my/MNhWPM8TDw9e770+BTOedWrSYxSagGwIG7f7Y733wG+k7YbWt+xMtk8DRnGPGEdcch5cOPqNrl/VEdpnq3ue9r84u/fB49flN0UCipO/M1C7uknEh3mzmo1DPmPEf+OENF5f4oHRHb5lZtti/7T/nmBZv2aLrdP/Xb9un9zeq7XFdpY/vnt9skKylj+hp6hVz5hWU3vkIzSagD8My7ln6ETGLx2nhb4ZBOZbCs5Xa4Rd0F6r9dZlKKtzz//3T49jt3AirH8DZmlV4p/r4r2sRl5NHzlZQpm/5J1vkm4VQB+VA3v/aX989Ll9sm2+CdasjH/Qz17HttoiA+rNRjSjHnCUkVEL/riclHQrzq6f/Hf2j8vXa6RiPhnSXDj/f3QcV1yP71Dz2N/Z0b8DRnGPGFdoKRyaHTDFuVkJBLImvdjlolslwO1MP86x/Wy5fZJUF/j808/dg/LZdw+hsxixL8LDB/uCPHsSPzjXSPblsFfT4bX7k7tZs/eBEsegvWv6e1Qa8r1TCtdcvsYy7/T2AO+JtrHkGGM+HeBkw+PZvUNuxxTJV5NIOir5sMd/di9db3eDlg52lf+K7Wb2d3/oHVeDrl9mlpMPvpOY/ewjOVvyDBG/LtAWWlZ5P3+fXujB/7307aF1+pFYQb+eYZe6MSOjd+zNrWb2SIQEf9eNODbgfi/u3YnLYEE5xmSY33PYkI9DRnGPGHdxNViiX8icYznpTuiIg6p+f3tnkVk3kC2LP8EdQ0HYNca2JE4vb2HkBH/zhJx+5ifpiGz9MonrFfG+ccz+WwASoL7dYRGa11q5wUdPnsrfW+72JZ/RPx7j+W/fsc+uPcI+MMxCU8pllaaW5ozXbP8ImzcPoaeoVeKf6+M84/ngod4Z9wNeAmyamMttKTYUDkt/5TE3xN7XjDNA76tDXqd4UV/Sx6a2VqvcxnFsXbbvnYvfbjrE6r+cng6atkxb/4a/nNNz9wrk1g9LDHib8gwJrFbN5h88BRYC4/869/cfeGnUjvJKd6tXbD8070m8M/HR69ZPlQnjovnl1MijVuL8lIo2vUU9HfcC/E0t7NqVTr5r5Vr7ex7e+Z+mcIeWDc+f0OGMU9YNyifdhZBVwF3130X/nxiaicFHW4Qa+GOdon3+Xe0joCTmsX6rz2cjUmyazt6NS1EQ1uDwbbi32TWnu0eJr2DoYcw4t8dvEU0ffou1oeHdFzWJsbn3xnxt4TZ3wDvPxhtDNrjr6fovzTSijfyfo56NebYc6Xn8u0Bv0z9Ys37zCzgeEyop6GHMOLfTcqP/yqLT3409ROcop2K2yfeAty/GZ6+Hl77Sez+N38ND52dej26SKvyJj22TkYS8vVP7UL7NsJPR8M7f0hLvTKFiJwmIh+LyFoRuaWdcueJiBKRmV2+mb8JGnZY1zM/TUNmMU9YGphz7KGpF375B9H3qbh9kolAc9xg639vj84C7iopLBLjdPu0qVJQ8Pl8qd3LnufwyQuplW+Pt37b/WskQETcwL3A6cBk4CIRmZygXBnwdeDdbt1w4c9gwTetixrL35BZjPingcKC6Lj5i5/9b+onphLtkyyFQrK0Eqk0KADN++GOuGiqBD78Npe33D77Rp7a5lhDUPAVpij+9joHLqsn8fKd8Oj5qZ3rpH4HvHhb589LjSOBtUqp9UopP/A4kKh79UPgp0D3pjQ7Z4sbt48hwxjxTzPP13aQ68eJc27AnnWw/n9tyySb1OVJIrL1O1K7d6IZxs7B30AL7G5bptWy/N0DRtOqYoPFmoJQWFDY9roPzoFfxBnMdqPmtsT/9f8Hn7yYWt0BHpwNz3079fJdYxiwxbFdY+2LICKHASOUUs+2dyERuUpEFovI4l27kkRAOax9l4n2MWSYXvmE5cQkrzjWfPpP3Bucw1NLalM7QdyxPv/fHgYPzWlbLtlSifGWvy0cDdtTuz8JXDzOOQjzr4PfHd6mJxEQfd9SryIc9/gc8ENZSYJonw3/gzrH96JUdOzDnXwMoV02LIR3/9h25nEqM63ThGjH/C+Amzoqq5T6s1JqplJqZlVVVeJCxvI39CC9UvxzYpJXHAd96gJ+7/piu2X+FozG0CtfaWpun2SWf7x/3l5msj5FRpBqjwAAIABJREFU8U/k3ncORm9YqF/fiI3eWVEwDQDXhNNQcQIVUG6qyjsI9Qw0w6+mwVNX6m1XF8XfJt4tlt70F7XACMf2cGufTRlwCPCaiGwEjgbmd3nQ1/F9mklehkzTK8U/F/G4XTxz/fH88JxDkpaZduK5kfdNUpzYPx8O60iYhp3WtkPMnJZhIM69XGRF2bxyF/zx+BRqnED9neJv9yxe/38xRQ6UT4bb98H4z6DiBiWDuBlU1o7PPxyG2iVwwLEOcVctf5t4sU9v+otFwHgRGSMiBcCFwHz7oFLqgFJqoFJqtFJqNPAOMEcp1cHkiiQ4/79mwNeQYYz4p5ExA0v48tGjoHwYjDg6esB6f8SkMZFdtU1uwpvf0YOcfqevvRF+faieeQux4lbicBcE4+L8PZavfd8G2L48Nmlcolj6RPucbh934snfA8uLIrNPCzyxZYK4qWpP/P0NbdNguLo5yTzeLZbMTdYFlFJB4FrgBWA1ME8ptVJE7hSRBD66buL4LkxWT0OmMekdMsGNq7S4/qBCb1+2QPum926IFKlTxbj2rdFivd4xWSp+lq1TzEqqoH6bfh8/ySve4m3ZH30fbAVvYfvl46+ZJJpoUL/iyHuv1wuOywSUm6rSBAO+kTodaCv+HS2Gkwhnw5VZyx+l1AJgQdy+25OUPalbN4sRf2P5GzKLMS8yhdMn73Jr90ZheWTXflUSPb5vU/R9/MQvp7jZfn1om+MnPuFbk2OdgU1vtK1fR+KfxBc/uJ/Dp9/G7eNhYFk7Yt6yv232065MZnJ+1jY+/yxlPU0Hxudv6EGM+GeSb22Am9dFtwujA9gHKI28D25bHi0TPwjsFDe3w6US7/OPF71mh/g/cp5ePjLZdSMVcVr+iTuFFc5onjjhDuKiuKCdzmQiyz++Hqmke3C6p0Jxbp5cXlfYWP6GHsSIfyYpHgAlA6PbnqhLJFBQEXnvr10RLeMUbYgVN7cXRuvBXOW0/Fc8GRtKCdAYl4J5/5bY7UQi6WxQkrhjCryOHoEr3uffgRcxkfiHArF1ScVnH7MgTkajfXoWp+VvBnwNGcaIf0/icAVNHDMy8t6739E7sKN8QFvBDot+e0OIk/d8k/+FpiEbX4fF9+vB4n9eoQtMmxvtXTzzjdh7H9gC/7gsKr4J3T6OBiWJ+Hucg7xxg5L/utEKZb10AVz6LB+UnhB7cssB7fpxupSWz9ML1NukIt5O91SGff49itPydxvxN2QWI/49zYCDYOYVzJh4UGSXN+QQM2ecfqA5xrLdsHUH63c1RvPrPPON2EVWSgfDl62F4RviZvo+fwusfApW/ENvJxLZmGifxD5/j9ch/oNjw1qLqkbrN6OPg9GfYl113NoALQegpQ4qHKHz4QA8e2PsthOl2qadaNfnn8uWf/S7dRm3jyHDGPHvaa7/AM76RTQuP56Xvh99v/JfMW6fQR4dCeR3ulec7h2PDwqiYwkJ8VrROgndPh0P+Hp9joHqz/0RvjBPv5/aNi9PaUlJ7I6mPboBKEkywxXaztBd9Fe4qyq2R+Qcm4j3+YcD8PytsOyJ5PforZgBX0MP0itDPUVkNjB73Lhx2a5K5iga0HGZ/3wNiivZqSoYJPspDh7ghAlVTN6vwA6a2fVxtLw7BfG33TkxFrPouQlO8U+0YDvgKXIIuq8MJsyCb66F4so2ZctLHXUpHw4L79Hvx302ef3iG6Xllojv3QClg/T7QHs+fz+8Y63mdejc5PfpjZgBX0MP0ist/1xM79Bpiio6LgPQtIetSgtrWbiOgSUFjCx0iPQWRxZhTwH4OhB/27Xj9I2f8weYeJp2OdmWdxLfeYzlb1NalXDZwYrysujGaMcyl1uXJK+fLeaBZp3szu6B2Ptb6+HJy6Pl89Tnb9w+hkzTK8W/T2BF/jQVDe2waK0l/qU0MaCkAG/LnsgxtfntaEG3D7wJxNmJPZvYKZpuL4w4Sq8stuPDtscdFBR2cH0H/cscDVHZ4Oj7aRfCNYv0+Ec89n2fukonu8MK/bRFfdnjUL81Wj4+OihvfP7mp2nILOYJyxYDJ8JxX2fDmY+xOVxF7ZjPJy1aZ00I+23wHAaUFsAgnR65SfmQXR9FC3oKksbnR7DnEcSL/6jj9PuNb+rXJOsIuAqKE+5PREW5Q/yP+j+Y8jm4aQ3M+hFUTYD+Y9qeZIv5ulf0qz24a898jh+I7mimcy7hsPbd5pdpyDDmEcsWLhd89k6GHTSFE/y/4t8jvxMzIcw/OdoYBHEzuuUx/l/wAgaW+ODzf+PD05/ilfD02Gu6U1hIxQ7ndIqkuwD6DdPjEHvW6jkBydYF6EQitqJCR0NRPhTOf0D3AOyQ10TXshslewKZXU87CV58CGp8Ogx/3MznXCImn3/Hq6oZDN3BiH+WqSgu4LCR/Xno7Y3UuaNjHCetOgtlDd4GiYrCgJICKOzH0EOO59XQjJhr/fyVDfz+tQSLtPiiaSUi4uh0l9h+9cJy3TP41SGxmTe7ikcLdYsr9d5CpMdhi79t+dviHy/2gbjtVFcy64U4U2S7U1hS02DoDkb8ewHfOm0SO+pamXZHdCWrHS1uAsU6umXM4Ojg8Jgq7QIaUFLAwqJTeGR4NDR07Z4AP3v+42j4pc2QQ+HWrVA80OH2cVr+lvgXlMWK55Rz28Tyd4X9riRhrYlm89qhmxHL3xb/uthXm3hL35+74h+WqMsuhSQXBkO3MOLfCzhqzAB8Hv2v+GHgS+xQFYRw0+TT4j++uj8nTqjiu2cczNiqqB99fHU5/2g5Eg76NOCI/58wSws5wJzfwtyHoaBERwL5G/WgqcOCXr6tmdG3PEuLuzh2cpi7gMSrvqRI+XCeKzuPH5R9P/FxW/zHnwrn/c3aZ1n+thVsz0huscU/TtzjE9zlsOUfcvwcg6HEobYGQ7ow4t8LEBH+efWxFHhc/C10Bke1/h6AHYV6QLS4sIAHLz+SK0+IjY6ZMLiMT3Y2oCw/uFj24p6GVhh1jC508JzohLKCUvjoWfjXV/USiBYvrdHRQ3sCPti7PnoDt7ftimGdweXixeHXs6IlyaQuO6z0kPOiMfzxPn9b/G1Rb4m3/PPH7RNy+PyDYWP7GzKLEf9ewiHD+nHDZybE7Fvh12Ggpf6diU5hwuAymvwhmsP63+hBi+mCFdvg8/fD5S/EzifwFrddBAZwWb75RgqheV/0gLuge+KPdk/tbUwSgWNb/t6itvH88YnNbFHvYctfRE4TkY9FZK2I3JLg+P+JyAoRWSoib4jI5ETXSYWQY2wnGDLib8gsRvx7EeMHxU7QemO/ju/37lmTsPyEwbp8vaWtBQQ5YnR/fvr8x4S9JTDy6NgTkoRp7m3RQrPLHxct5C7oWr59BwNKCmjyh2gJJFhYPSL+xdFxh3ifv41T/KunwgUP621/ky57267YctDtmH/RqTXvBU4HJgMXJRD3x5RSU5VS04GfoRd07xIhZSx/Q8/RK9M79FWOHluJxyWRH/6L+6qhEJh5ecLy4wdrv/5G9xgGA6qkijnTh7Fo44fsqG9hSL+4xdSTpH7YdsAPlLCtJe5xcHu6Lf5VpbpB2VnXysjKuMbHFn9PYXSCUzgF8feVR0M+A42612A3Hk7x/+FAuH1vTPx8JzkSWKuUWg8gIo8DZwOr7AJKKacfqoRujNXGWv69z+cfCASoqamhpaWl48KGjFNYWMjw4cP1inpdwIh/L6LU5+HDH8yirjnA3D+/w4bd8JUxL/HXw45IWL5fkf6nX/TRsRzl6s/0o09j1AAtsJv3NLUVf29iy39HXRPQn82N7tgnwuWlWwO+wNhBOjpp7a765OLvtPwjbp+4+7bs13mMWuv0nAG7vL8pOjbh8rSNBmrYoct3jWGAcyGEGvj/7Z17WFVV2sB/i+sRkIvcVJQ0xgsiIoKXGRvvzGhldpGoKTNM/frKvPTMU6ZN+ZU9NZZ+5Yw1Uqkxk+OUjqVOZlKU9akVFkmiphkqpoCoR1G5HFjfH/twLnAO58TlnIOs3/Och332Xnuvl8Xi3Wu9613vy/CGhYQQDwOPAn7AOFsPEkLMBmYDxMbG2ipiveDrgSP/4uJiOnfuTK9evRDKFdWtSCkpLy+nuLiY3r1tbJZ0AmX28TB0vt5EBeuYMbIXoLmBNsX4/lHU4YUh9gZmjOzNdUYFe/ycjc1OduL+VNXUMjGhKxWywcsC2eKRf/3s5PCZisYX65PM+/iZbf4fP6Mt4jbcqVtaCKuGacnprUb+V8yzBt8A6zULgAutsF/BAVLKVVLKOOBx4Ek7ZbKklKlSytTISNsL4AaLF60nKv/KykrCw8OV4vcAhBCEh4e3aBamRv4eyr0jruPW5Bg665qe0q3IGExdnSQsUFOGNbVa+cc27icuMoiU6yx87OMnQ94aq/sNQd04XhnNA/FRFBxtELentqbFyj9Y50v3EB0/lNhYiDW5dfqaw1KUH4XP/tw4bIMlnULNyr/6snkW4N8ZKsqsy1440Xjtw3lOARbJB+hhPGePDcBrza3M0uxTW+d5Zh9AKX4PoqV/CzXy91CEEA4VP2imn3rFD+BrERTm1dyjPPT2Pj77wagQ48bByPmQ9qypTP7U3VTiT3Swji6h1puxyvUVLVb+oI3+D5+xpfyNZh8vH+v8AUX/Z638fRrMSAZONSv8mivme/2DG3szXTjeEtG/BvoIIXoLIfyAu4AtlgWEEH0svt4EHGluZQbl7aNwIUr5X4N8MPe3TIiP5uNDpXxQcIbpa76ivKKK7QWnqRu/BFKmm8qerdDMK+GBfvQNtja17Nh/nIpq8wj0k6jpNId+XTtztKyi8SJm2jNa2smQGOs4P2f2m3f2AoRdZz4e9l8QO9xi5H/FPGvQWYSxqKdh7uJfgJTSAMwBdgAHgXeklAeEEM8IIW4xFpsjhDgghMhHs/s3r5FosODrgWYfxbWFRyp/IcRkIUSWXq93XFjRiAHdg/nD8J5W5+598yv+++1vyD1cahXrp94HPyLIn9q+kzhRF8kqg6bX/IWB1bU3A/Bb1vBZzOxmydM3ujPVhrrG6xDxk2HhCWs/f2hs7w+1WCC9cZn209Lbpx5/i/wB9bTQ5i+l/EBK2VdKGSelfM547ikp5Rbj8TwpZYKUcrCUcqyU8kBz6zJI879jjQd6+3QkDAYboUeuMTzS5i+l3ApsTU1NneVuWdorg3tam3AOnta8YE6eu2LlSbNocwGg+eMPGZjAjLw3ubvTl3BmC74Y+MvJ6/kL6wHw922ey2Q/46LvD2cuWYWnsMJWKOqgaM1bx5b939KDp17B+zcY+f/2jzByXjMkdg+WZp9H0/o2UdL9/M/WAxT+fNFxwV/AgO7BPD05wWG5W2+9lZMnT1JZWcm8efOYPXs2H374IYsWLaK2tpaIiAg+/vhjKioqeOSRR8jLy0MIwdNPP80dd9xBUFAQFRWaA8LGjRvZtm0b69at4/7770en0/Htt98ycuRI7rrrLubNm0dlZSWdOnVi7dq19OvXj9raWh5//HE+/PBDvLy8mDVrFgkJCaxcuZL33nsPgJ07d/Lqq6+yefPmVm2j1sQjlb+i5XQJ9LN5/miZ2evmtIgyHfv5eNEjLICPFozG8P152AjxUTqr5c1OzVT+v4oKwkvA658f48zFSjJH2nBNs5UzeMh9WurHfpOg6HNrV1X/IJiVC6+PNZ+zNPvM+w5Cr2vxDmVXYrCYiCfH2gmGp2DNmjV06dKFq1evMnToUKZMmcKsWbPYtWsXvXv35ty5cwA8++yzhISEUFCgDXDOnz/f1GMBzZ119+7deHt7c/HiRT7//HN8fHzIyclh0aJFbNq0iaysLIqKisjPz8fHx4dz584RFhbGQw89RFlZGZGRkaxdu5YZM2zvz/EUlPK/hsmaloKXEPysv8qBUxc5VHKJo6Wa8tfPP86YF3Jt3ufTNw2uH0tl0pPwT3Ogt6SezUur2cnPm+TYMPYdP883Jy7YVv62YvtH9ocnTmlB6S6fhQG3WF8Pj7P+Xm/28faDsF7NktWdGGT7eVE5M0JvK1auXGkaUZ88eZKsrCxGjRpl8nfv0kXLj52Tk8OGDRtM94WFOX6hpqen4+2tDXL0ej3Tp0/nyJEjCCGoqakxPffBBx/Ex8fHqr5p06bxj3/8g8zMTPbs2UN2dnYr/cZtg1L+1zC/S+hq9f2xjd+x40AJ1YY6Pi26TBV+RHX2Z2ivBsnk/QLhvveIqzYQEZRrWhRObVjuFzAkNpR9x7WR1+UqA4H+Dbqel42uGBhh3pswwUZkUF2Dl5G/8XsreCi5A0Nd+5TblXz66afk5OSwZ88eAgICGDNmDIMHD+bQoUOObzZi6SLZ0E8+MNDs7vynP/2JsWPHsnnzZoqKihgzZkyTz83MzGTy5MnodDrS09NNLwdPRfW2DsSkgd3QX63ho8IzfHywlPBAP/Y+MZ5V9wyxWT7Az4e8J9O4M7UHiTEhBDvhemqPB0fHERag3V96qarR9VWf/tjoHN2SnHu4VwNvHzs7mT0d5d3pGL1eT1hYGAEBARw6dIi9e/dSWVnJrl27+OmnnwBMZp+0tDRWrVplurfe7BMdHc3Bgwepq6tr0iav1+uJiYkBYN26dabzaWlprF692rQoXF9f9+7d6d69O0uXLiUzM7P1fuk2Qin/DsSovpH0Cg/ghe2H+PDAGcbHRzmVLnDZ1CS2PnJDi+oOD/LnL3drL5mSi413Jb6447B2YDkD6OSE3fvx4+b0l/Wxi6LiWyKq21DunY6ZOHEiBoOB+Ph4Fi5cyIgRI4iMjCQrK4vbb7+dpKQkMjIyAHjyySc5f/48AwcOJCkpidxczcz5wgsvcPPNN/Ob3/yGbt262a3rscce44knniA5OdnK+2fmzJnExsYyaNAgkpKSWL9+venaPffcQ8+ePYmP9/w+6NnzEkWr4u0lePqWBDLXfg3ArYNjXFp/dLAxyJuNkT/Af1fP43/nTkP3t1QI0kxW5y5Xs/3709w1NBZvWy8qy5DVV7S8BEQ2HRLDU6lVyt8h/v7+bN++3ea1SZMmWX0PCgrirbfealRu6tSpTJ06tdF5y9E9wK9//Wt++MEcUXfp0qUA+Pj4sGLFClasaBzA9YsvvmDWrPbhpKiUfwdjbL8olt0xiD3Hyhl+fbhL644K1gFQ2mDkX2dUetvrhvNH727ELThgGsVn7yni5ZwjVBvqbC8UW5JwG3z7dxg5t9VldwVq5N++SUlJITAwkOXLl7tbFKdQyr8DcufQntw5tKfjgq1MsM4Hna8Xx8utN3tZzgROX6gkrk8P03cv4+LcO3nFjpV/aE+Y83XrCexiPDWej8I59u3b524RfhHK5q9wGUIIxvWPYv1XJ/j+lHn3dvF588vgZ731hq6LVzX3uoazhWsRNfJXuBKl/BUu5fnbB+HrLcjeU8TCTfs5UX6FkxbKf2dhCVKaleAFo/Ivv1xNlcFGNrBrCGXzV7gSZfZRuJSQTr78bkBX3skrBuBsRRVxUUH4egvG9ItiZ2EJe4+d49dx2nqE/qo5FWPpxSp6dmmfbpzOoCJ5KlyJGvkrXM64/uawEjkHS1n92TF+FdWZ529PBODAz2aTkP6KWfmXXKxkZ2GJaZeyPUovVTLupU9584ufWlnytkWN/BWuRCl/hctJ7dXYfz/Az5uIIH8igvx4/fNjHDEmf9FfraGXMTvZ7h/LmZWdx40rP290f0GxXotYCnx74gLHzl7m2W2FXLhS3aisp1IrlfJXuA6l/BUuJya0YbpIGB9fPxsQlFys4r41XwFw4Wo1/bpqMXtW7NR8rqsNdVbrAgCT//oFmWu/pq5O8qNF8LrvittPWHC14Nv6BAXZiSKrUDZ/hesRQvCfuTfw5hc/8e9vTvHRglGmUM93pMSw+rNjnNZXkvLsTsovVxPbJYD0lB68u6/Y9IyntxxgVJ9IJgyI5nKVefdlwSk9nx4qI9DPmys1teSfuMDovrZz5jop60TgFcAbeENK+UKD648CMwEDUAbMkFI2K31YbW0dY6uWs3leGqGOi7uX7QvhTEHrPrNrIkx6wXG5dojBYPC4WD9q5K9wCwndQ3hxahJfLRpP3+jOpt27j/2+Py9nDAY0Dx8AKeHF9CQW3dif5FhNLWbvOc7M7DwA/rP/tOm5d67ew1dF54gO1tEnKoj8k47D+NpDCOENrAImAQOAu4UQAxoU+xZIlVIOAjYCy5pbn6FO8pPshldod8eFOygLFy60itezZMkSli5dyvjx4xkyZAiJiYm8//77Tj2roqLC7n3Z2dmm8A3Tpk0DoKSkhNtuu42kpCSSkpLYvXs3RUVFDBw40HTfSy+9xJIlSwAYM2YM8+fPJzU1lVdeeYWtW7cyfPhwkpOTmTBhAiUlJSY5MjMzSUxMZNCgQWzatIk1a9Ywf/5803Nff/11FixY0Ox2s4VnvYoUHQpvL2Ha9Wt5blJiVw6XxDG0Vxgz1uWZzD6zR8Uxe1QcE1/exSFjTuD9xRdY/F4Bg3uGcvjMJa7WaO6g9464jj7RQYR0an4wOmAYcFRKeQxACLEBmAIU1heQUlrGxd4L3NvcyuoXfH2ciLfkdtw0Qs/IyGD+/Pk8/PDDALzzzjvs2LGDuXPnEhwczNmzZxkxYgS33HKLwwTnOp2OzZs3N7qvsLCQpUuXsnv3biIiIkyB2+bOncvo0aPZvHkztbW1VFRUOMwRUF1dTV6eNkg5f/48e/fuRQjBG2+8wbJly1i+fLnNvAO+vr4899xzvPjii/j6+rJ27VpWr17d0uazQil/hcfh7+PN4xO1+Dz5T6U1iiaa/cAwXs39kXW7i0j/2x4C/X1Yc/9QMtd9zXcnLzBpYFdm3OBgN7BzxACWSYCLgeFNlH8AsB14xgnqbf42YxgpAEhOTqa0tJSff/6ZsrIywsLC6Nq1KwsWLGDXrl14eXlx6tQpSkpK6Nq1a5PPklKyaNGiRvd98sknpKenExERAZjj9X/yySemGP3e3t6EhIQ4VP71QeZASxSTkZHB6dOnqa6uNuUfsJd3YNy4cWzbto34+HhqampITEz8ha3VNMrso/BoQgP8GkUejeqsY8EELc1hlaGOB0fH0SXQz+QV5I69AEKIe4FU4EU712cLIfKEEHllZWU2n2Ee+at/y6ZIT09n48aN/Otf/yIjI4O3336bsrIy9u3bR35+PtHR0Y3i9NuiufdZ4uPjQ51FWI6m8gM88sgjzJkzh4KCAlavXu2wrpkzZ7Ju3TrWrl3bJiGiVS9TtEtCAnx5OWMwg3qE8IfhWoL3IGOCmMgg/9aq5hRgGQSpB1aJLTWEEBOAxcAtUkqbIUullFlSylQpZWpkpO0F6PqRvxr4N01GRgYbNmxg48aNpKeno9friYqKwtfXl9zcXI4fd2693d5948aN491336W8XIsSW2/2GT9+PK+99hoAtbW16PV6oqOjKS0tpby8nKqqKrZt29ZkffX5ASyjjdrLOzB8+HBOnjzJ+vXrufvuu51tHqdRyl/Rbrk1OYYtc24wmYVCjcli/HxarVt/DfQRQvQWQvgBdwFbLAsIIZKB1WiKv7QlldXW1eHjJRzaqjs6CQkJXLp0iZiYGLp168Y999xDXl4eiYmJZGdn07+/cyG97d2XkJDA4sWLGT16NElJSTz66KMAvPLKK+Tm5pKYmEhKSgqFhYX4+vry1FNPMWzYMNLS0pqse8mSJaSnp5OSkmIyKYH9vAMAd955JyNHjnQqBeUvRkrpsZ+UlBSpUDiL/mq1fHbrAXmlyuBUeSBPOuiDwI3AD8CPwGLjuWfQlD1ADlAC5Bs/Wxw9016/fu/bYjln/TfNb4A2prCw0N0idDhuuukmmZOTY/e6rb+JM/1aSum6BV8hxPVoU+MQKWXjTAoKRQsJ1vny5M0NPTFbhpTyA+CDBueesjie0Fp1TRkcwxQXJ9hReCYXLlxg2LBhJCUlMX78+DapwynlL4RYA9wMlEopB1qcb3IDjCVSc5d7QAixsWUiKxQKhfMUFBSYfPXr8ff358svv3STRI4JDQ21yiLWFjg78l8H/BXIrj9hsQEmDc0F7mshxBa0F8HzDe6fIVtoD1UoFO5HStnu1iQSExPJz893txitjmxhLCinlL+UcpcQoleD0zY3wEgpn0ebJSgUimsInU5HeXk54eHh7e4FcK0hpaS8vBydTue4sB1aYvP/RRtghBDhwHNAshDiCeNLwla52cBsgNjY2BaIp1AoWpMePXpQXFyMvX0KCtei0+no0aOH44J2cNmCr5SyHHjQiXJZQBZAamqqCnOoUHgIvr6+pl2pivZPSxyindoAo1AoFArPoyXK3+EGGIVCoVB4Jk4pfyHEP4E9QD8hRLEQ4gEppQGYA+wADgLvSCkPtIZQQojJQogsvb79JOJQKBSK9oRoqbtQWyKEKAPsBeqIAM66UBx7eIocoGSxhz1ZrpNSNj/TSzNpJ/0alCz28BRZWtSvPVr5N4UQIk9KmarkMKNksY0nyeIIT5JVyWIbT5GlpXKowG4KhULRAVHKX6FQKDog7Vn5Z7lbACOeIgcoWezhSbI4wpNkVbLYxlNkaZEc7dbmr1AoFIrm055H/gqFQqFoJkr5KxQKRQek3Sl/IcREIcRhIcRRIcRCN9RfJIQoEELkCyHyjOe6CCF2CiGOGH+2Qc41La+CEKJUCPG9xTmbdQuNlcZ22i+EGOICWZYIIU4Z2yZfCHGjxbUnjLIcFkL8vhXl6CmEyBVCFAohDggh5hnPu6VdWoI7+7bq103K4vJ+bXx22/ZtZ9J9ecoHLVfAj8D1gB/wHTDAxTIUARENzi0DFhqPFwJ/bqO6RwFDgO8d1Y2WfnA7IIARwJcukGUJ8EcbZQcY/1b+QG/j39C7leToBgwxHndGS7k4wF3t0oLfw619W/Vrz+rXxue3ad9ubyN/Uw4BKWU1sAGck21rAAACP0lEQVSY4maZQJPhLePxW8CtbVGJlHIXcM7JuqcA2VJjLxAqhOjWxrLYYwqwQUpZJaX8CTiK9rdsDTlOSym/MR5fQgs1EoOb2qUFeGLfVv26adqsXxtladO+3d6Uv60cAq5OeiqBj4QQ+4SWewAgWkp52nh8Boh2oTz26nZXW80xTjnXWJgJXCKL0BIOJQNf4nnt4gh3y6X6ddO4rV9D2/Tt9qb8PYEbpJRDgEnAw0KIUZYXpTb/cov/rDvrNvIaEAcMBk4Dy11VsRAiCNgEzJdSXrS85gHt0h5Q/do+buvX0HZ9u70pf7fnEJBSnjL+LAU2o03zSuqnV8afrsxXbK9ul7eVlLJESlkrpawDXsc8BW5TWYQQvmj/HG9LKf9tPO0x7eIkbpVL9Wv7uKtfQ9v27fam/N2aQ0AIESiE6Fx/DPwO+N4ow3RjsenA+66SqYm6twD3GT0ARgB6i6lim9DAvngbWtvUy3KXEMJfCNEb6AN81Up1CuBN4KCUcoXFJY9pFydxW99W/bpp3NGvjfW2bd9urZVpV33QVrR/QFtZX+ziuq9HW93/DjhQXz8QDnwMHAFygC5tVP8/0aadNWj2vAfs1Y224r/K2E4FQKoLZPm7sa79xo7YzaL8YqMsh4FJrSjHDWjT3v1AvvFzo7vapT32bdWvPa9fu6Jvq/AOCoVC0QFpb2YfhUKhULQCSvkrFApFB0Qpf4VCoeiAKOWvUCgUHRCl/BUKhaIDopS/QqFQdECU8lcoFIoOyP8DB/nU+yY47BEAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "h_model.evaluate(X_test_scaled, y_test, return_dict=True)"
      ],
      "metadata": {
        "id": "R_zOL1o-IpyH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b87090f-fc8a-472e-f912-dbcc8a09e4e8"
      },
      "execution_count": 463,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 0s 4ms/step - loss: 0.4170 - accuracy: 0.8846\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.8846153616905212, 'loss': 0.41696617007255554}"
            ]
          },
          "metadata": {},
          "execution_count": 463
        }
      ]
    }
  ]
}